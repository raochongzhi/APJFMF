{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb28321-238b-4db2-b4ef-c36dc08ec153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import datetime\n",
    "import time\n",
    "from transformers import BertConfig, BertModel, BertTokenizer, BertForMaskedLM\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import word2vec, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad166e6-d167-471d-914e-2959eb3db314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 设置随机数种子\n",
    "setup_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ddf018-af0f-46bf-b4e3-aff355a1a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_user_job_all_test1.csv', dtype = {'UserID': 'str', 'JobID': 'str','label': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7194e91-187f-4cf1-91cf-a886a5d46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_job = dataset['skill_entity_en_job'].values\n",
    "skill_user = dataset['skill_entity_en_user'].values\n",
    "\n",
    "skill_job_emb = []\n",
    "for skills in skill_job:\n",
    "    skill_job_emb.append(skills.split(','))\n",
    "dataset['skill_job'] = skill_job_emb\n",
    "\n",
    "skill_user_emb = []\n",
    "for skills in skill_user:\n",
    "    skill_user_emb.append(skills.split(','))\n",
    "dataset['skill_user'] = skill_user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeddd2d0-e037-4adf-a7de-1a4a0a0061e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_array = np.concatenate((skill_job_emb,skill_user_emb),axis=0)\n",
    "# # w2v_model = word2vec.Word2Vec(text_array, size=100, window=5, min_count=2, workers=8, iter=10, sg=1)\n",
    "# w2v_model = word2vec.Word2Vec(text_array, size=8, window=5, min_count=2, workers=8, iter=10, sg=1)\n",
    "# w2v_model.save('word2vec_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6261cdc7-f7b9-438d-8726-0eb1084b9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffe314b-5cf7-4406-82e8-684b22e85778",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_present_list = list(w2v_model.wv.index2word)\n",
    "dataset['skill_job'] = dataset['skill_job'].apply(lambda x:[i for i in x if i in word_present_list])\n",
    "dataset['skill_user'] = dataset['skill_user'].apply(lambda x:[i for i in x if i in word_present_list])\n",
    "# 先用列平均值，后面看情况再改\n",
    "dataset['skill_job'] = dataset['skill_job'].apply(lambda x: np.mean([np.array(w2v_model.wv[i]).reshape(1,8) for i in x], axis=0))\n",
    "dataset['skill_user'] = dataset['skill_user'].apply(lambda x: np.mean([np.array(w2v_model.wv[i]).reshape(1,8) for i in x], axis=0))\n",
    "\n",
    "skill_user_1 = []\n",
    "skill_user_2 = []\n",
    "skill_user_3 = []\n",
    "skill_user_4 = []\n",
    "skill_user_5 = []\n",
    "skill_user_6 = []\n",
    "skill_user_7 = []\n",
    "skill_user_8 = []\n",
    "\n",
    "skill_job_1 = []\n",
    "skill_job_2 = []\n",
    "skill_job_3 = []\n",
    "skill_job_4 = []\n",
    "skill_job_5 = []\n",
    "skill_job_6 = []\n",
    "skill_job_7 = []\n",
    "skill_job_8 = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    try:\n",
    "        skill_job_embedding = dataset.loc[i, 'skill_job'][0].tolist()\n",
    "        skill_job_1.append(skill_job_embedding[0])\n",
    "        skill_job_2.append(skill_job_embedding[1])\n",
    "        skill_job_3.append(skill_job_embedding[2])\n",
    "        skill_job_4.append(skill_job_embedding[3])\n",
    "        skill_job_5.append(skill_job_embedding[4])\n",
    "        skill_job_6.append(skill_job_embedding[5])\n",
    "        skill_job_7.append(skill_job_embedding[6])\n",
    "        skill_job_8.append(skill_job_embedding[7])\n",
    "    except:\n",
    "        skill_job_1.append(0)\n",
    "        skill_job_2.append(0)\n",
    "        skill_job_3.append(0)\n",
    "        skill_job_4.append(0)\n",
    "        skill_job_5.append(0)\n",
    "        skill_job_6.append(0)\n",
    "        skill_job_7.append(0)\n",
    "        skill_job_8.append(0)\n",
    "    skill_user_embedding = dataset.loc[i, 'skill_user'][0].tolist()\n",
    "    skill_user_1.append(skill_user_embedding[0])\n",
    "    skill_user_2.append(skill_user_embedding[1])\n",
    "    skill_user_3.append(skill_user_embedding[2])\n",
    "    skill_user_4.append(skill_user_embedding[3])\n",
    "    skill_user_5.append(skill_user_embedding[4])\n",
    "    skill_user_6.append(skill_user_embedding[5])\n",
    "    skill_user_7.append(skill_user_embedding[6])\n",
    "    skill_user_8.append(skill_user_embedding[7])\n",
    "\n",
    "\n",
    "dataset['skill_user_1'] = skill_user_1\n",
    "dataset['skill_user_2'] = skill_user_2\n",
    "dataset['skill_user_3'] = skill_user_3\n",
    "dataset['skill_user_4'] = skill_user_4\n",
    "dataset['skill_user_5'] = skill_user_5\n",
    "dataset['skill_user_6'] = skill_user_6\n",
    "dataset['skill_user_7'] = skill_user_7\n",
    "dataset['skill_user_8'] = skill_user_8\n",
    "\n",
    "dataset['skill_job_1'] = skill_job_1\n",
    "dataset['skill_job_2'] = skill_job_2\n",
    "dataset['skill_job_3'] = skill_job_3\n",
    "dataset['skill_job_4'] = skill_job_4\n",
    "dataset['skill_job_5'] = skill_job_5\n",
    "dataset['skill_job_6'] = skill_job_6\n",
    "dataset['skill_job_7'] = skill_job_7\n",
    "dataset['skill_job_8'] = skill_job_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb9726d-bf7d-4161-987b-2f23706b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 稠密特征\n",
    "dense_feas = ['岗位薪资下限(K)','岗位薪资上限(K)','work_length','总分','岗位招聘人数']\n",
    "\n",
    "# 文本特征\n",
    "vec_feas = ['skill_job_1','skill_job_2','skill_job_3','skill_job_4',\n",
    "            'skill_job_5','skill_job_6','skill_job_7','skill_job_8',\n",
    "            'skill_user_1','skill_user_2','skill_user_3','skill_user_4',\n",
    "            'skill_user_5','skill_user_6','skill_user_7','skill_user_8']\n",
    "\n",
    "text_feas = ['岗位名称', '岗位描述', 'experience']\n",
    "\n",
    "# 稀疏特征\n",
    "## TODO userid jobid应该放进去吗\n",
    "sparse_feas_user = ['UserID','性别','专业']\n",
    "sparse_feas_job = ['JobID','企业融资阶段','企业人员规模','企业休息时间','企业加班情况','岗位一级类别','岗位三级类别','岗位工作经验','岗位招聘类型'] # '岗位二级类别'\n",
    "sparse_feas_match = ['match_degree','match_loc_job','match_loc_corp']\n",
    "sparse_feas = sparse_feas_user + sparse_feas_job + sparse_feas_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a216ad15-c327-481a-9221-17acdd5f5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseFeature(feat, feat_num, embed_dim=8):\n",
    "    # if len(dataset[feat].unique()) < embed_dim:\n",
    "    #     embed_dim = len(dataset[feat].unique())\n",
    "    return {'feat':feat, 'feat_num':feat_num, 'embed_dim':embed_dim}\n",
    "\n",
    "def denseFeature(feat):\n",
    "    return {'feat':feat}\n",
    "\n",
    "def vecFeature(feat):\n",
    "    return{'feat':feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8c94ee-5164-41c9-995a-1be525d8fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 8\n",
    "feature_columns = [[denseFeature(feat) for feat in dense_feas]] +[[sparseFeature(feat, len(dataset[feat].unique()), embed_dim=embed_dim) for feat in sparse_feas]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff5572d-cfeb-46c5-8901-5820feae1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_feas:\n",
    "    le = LabelEncoder()\n",
    "    dataset[feat]=dataset[feat].astype('str')\n",
    "    dataset[feat] = le.fit_transform(dataset[feat])\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "dataset[dense_feas] = mms.fit_transform(dataset[dense_feas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f2baf7-9f67-492b-b7e1-8d60d08308db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_DeepFM = dataset[dense_feas + sparse_feas + vec_feas + ['label']]\n",
    "x_DeepFM = dataset_DeepFM.drop('label', axis=1).values\n",
    "y_DeepFM = dataset_DeepFM['label'].values\n",
    "x_tensor = torch.FloatTensor(x_DeepFM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538cb434-5c9c-4759-b21d-3dca87220b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = torch.LongTensor(y_DeepFM.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2c0c07b-4ed5-45c2-85a9-55cd8e235083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_text = dataset[text_feas]\n",
    "# job_t = dataset['text_job']\n",
    "# user_t = dataset['text_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5551e17d-9295-4f5e-a089-4f63748b9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/root/autodl-fs/bert_wwm_ext_chinese_pytorch/config.json'\n",
    "model_path = '/root/autodl-fs/bert_wwm_ext_chinese_pytorch/pytorch_model.bin'\n",
    "vocab_path = '/root/autodl-fs/bert_wwm_ext_chinese_pytorch/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720211fa-7e97-41d6-8c2f-89f51c3868dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTextNet(nn.Module):\n",
    "    def __init__(self, code_length):\n",
    "        super(BertTextNet, self).__init__()\n",
    "\n",
    "        modelConfig = BertConfig.from_pretrained(config_path)\n",
    "        self.textExtractor = BertModel.from_pretrained(\n",
    "            model_path, config=modelConfig)\n",
    "        embedding_dim = self.textExtractor.config.hidden_size\n",
    "\n",
    "        self.fc = nn.Linear(embedding_dim, code_length)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, tokens, segments, input_masks):\n",
    "        output = self.textExtractor(tokens, token_type_ids=segments, attention_mask=input_masks)\n",
    "        text_embeddings = output[0][:, 0, :]\n",
    "        # output[0](batch size, sequence length, model hidden dimension)\n",
    "\n",
    "        features = self.fc(text_embeddings)\n",
    "        features = self.tanh(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a63ab0e1-eb47-4a12-b2cc-cce104f82266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转为32维向量\n",
    "textNet = BertTextNet(code_length=32)\n",
    "tokenizer = BertTokenizer.from_pretrained(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00410491-a396-4015-9d29-fad9d2b90bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_emb(texts):\n",
    "    tokens, segments, input_masks = [], [], []\n",
    "    for text in texts:\n",
    "        if len(text) > 400:\n",
    "            text = text[-100:]\n",
    "        # tokenized_text = tokenizer.tokenize(text)  # 用tokenizer对句子分词\n",
    "        # print(tokenized_text) # ['[CLS]', '今', '天', '天', '气', '不', '错', '，', '适', '合', '出', '行', '。', '[SEP]']\n",
    "        # indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)  # 索引列表\n",
    "        indexed_tokens = tokenizer(text)\n",
    "        indexed_tokens= indexed_tokens['input_ids']\n",
    "        # print(indexed_tokens) # [101, 791, 1921, 1921, 3698, 679, 7231, 8024, 6844, 1394, 1139, 6121, 511, 102]\n",
    "        tokens.append(indexed_tokens)\n",
    "        segments.append([0] * len(indexed_tokens))\n",
    "        input_masks.append([1] * len(indexed_tokens))\n",
    "\n",
    "    max_len = max([len(single) for single in tokens])  # 最大的句子长度\n",
    "\n",
    "    for j in range(len(tokens)):\n",
    "        padding = [0] * (max_len - len(tokens[j]))\n",
    "        tokens[j] += padding\n",
    "        segments[j] += padding\n",
    "        input_masks[j] += padding\n",
    "    # segments列表全0，因为只有一个句子1，没有句子2\n",
    "    # input_masks列表1的部分代表句子单词，而后面0的部分代表paddig，只是用于保持输入整齐，没有实际意义。\n",
    "    # 相当于告诉BertModel不要利用后面0的部分\n",
    "\n",
    "    # 转换成PyTorch tensors\n",
    "    tokens_tensor = torch.tensor(tokens)\n",
    "    segments_tensors = torch.tensor(segments)\n",
    "    input_masks_tensors = torch.tensor(input_masks)\n",
    "\n",
    "    # ——————提取文本特征——————\n",
    "    text_hashCodes = textNet(tokens_tensor, segments_tensors, input_masks_tensors)  # text_hashCodes是一个32-dim文本特征\n",
    "    # print(text_hashCodes)\n",
    "    return text_hashCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f1df5c-33d8-48af-b030-c7dd41a89289",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_job = []\n",
    "for contents in dataset[\"岗位描述\"].values:\n",
    "    content = re.split(r'[：；。]', contents)\n",
    "    if len(content) > 10:\n",
    "        content = content[:10]\n",
    "    else:\n",
    "        pad_length = 10 - len(content)\n",
    "        for i in range(pad_length):\n",
    "            content.append('')\n",
    "    bert_emb_job.append(content)\n",
    "# 存储到jobset中text列中\n",
    "dataset[\"text_job\"] = bert_emb_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fc3543e-f155-44fe-95b1-a76199b50e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_emb_user = []\n",
    "for contents in dataset[\"experience\"].values:\n",
    "    content = re.split(r'[：；。]', contents)\n",
    "    if len(content) > 5:\n",
    "        content = content[:5]\n",
    "    else:\n",
    "        pad_length = 5 - len(content)\n",
    "        for i in range(pad_length):\n",
    "            content.append('')\n",
    "    bert_emb_user.append(content)\n",
    "# 存储到userset中text列中\n",
    "dataset[\"text\"] = bert_emb_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23b844d1-645d-4521-805b-f2a16b9dd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_job_list = []\n",
    "for content_list in bert_emb_job:\n",
    "    # print(content_list)\n",
    "    content_tensor = bert_emb(content_list)\n",
    "    # print(content_tensor)\n",
    "    x_job_list.append(content_tensor.tolist())\n",
    "job_tensor = torch.FloatTensor(x_job_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f1069c-59e9-4caa-a52f-4bc10c8fd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_user_list = []\n",
    "for content_list in bert_emb_user:\n",
    "    # print(content_list)\n",
    "    content_tensor = bert_emb(content_list)\n",
    "    # print(content_tensor)\n",
    "    x_user_list.append(content_tensor.tolist())\n",
    "user_tensor = torch.FloatTensor(x_user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50332b97-8386-4170-9215-51fa7b9f4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_tensor = torch.stack([bert_emb(content_list) for content_list in bert_emb_job], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3b7e3bd-142c-4422-92f6-bf70e4ba6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_tensor = torch.stack([bert_emb(content_list) for content_list in bert_emb_user], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf0d338-b786-446f-af2c-b8cb858efc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobUserDataset(data.Dataset):\n",
    "    '''\n",
    "    Expected data shape like:(data_num, data_len)\n",
    "    '''\n",
    "    def __init__(self, job, user, deepfm, label):\n",
    "        self.job = job\n",
    "        self.user = user\n",
    "        self.deepfm = deepfm\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is None:\n",
    "            return self.job[idx], self.user[idx], self.deepfm[idx]\n",
    "        return self.job[idx], self.user[idx], self.deepfm[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca3ea0d6-914d-49d0-8d25-dd8d62e46585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_val_split(x1, ratio_train, ratio_test, ratio_val):\n",
    "#     x1_train, x1_middle = train_test_split(x1, test_size=1-ratio_train, random_state=20)\n",
    "#     ratio = ratio_val/(ratio_test + ratio_val)\n",
    "#     x1_test, x1_validation = train_test_split(x1_middle, test_size=ratio, random_state=20)\n",
    "#     return x1_train, x1_test, x1_validation\n",
    "\n",
    "def train_test_val_split(x1,x2,x3,y, ratio_train, ratio_test, ratio_val):\n",
    "    x1_train, x1_middle,x2_train, x2_middle,x3_train, x3_middle,y_train, y_middle = train_test_split(x1,x2,x3,y, test_size=1-ratio_train, random_state=20)\n",
    "    ratio = ratio_val/(ratio_test + ratio_val)\n",
    "    x1_test, x1_validation,x2_test, x2_validation,x3_test, x3_validation,y_test, y_validation = train_test_split(x1_middle,x2_middle,x3_middle,y_middle, test_size=ratio, random_state=20)\n",
    "    return x1_train, x1_test, x1_validation,x2_train, x2_test, x2_validation,x3_train, x3_test, x3_validation,y_train, y_test, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfb6934a-163b-4d51-885e-5f1795828c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job_tensor,test_job_tensor,val_job_tensor,train_user_tensor,test_user_tensor,val_user_tensor,train_x_tensor,test_x_tensor,val_x_tensor,train_y_tensor,test_y_tensor,val_y_tensor = train_test_val_split(job_tensor,user_tensor,x_tensor,y_tensor, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e5e1e8b-09ea-4d9f-9c22-f40571acd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = JobUserDataset(train_job_tensor, train_user_tensor, train_x_tensor, train_y_tensor)\n",
    "test_datasets = JobUserDataset(test_job_tensor, test_user_tensor, test_x_tensor, test_y_tensor)\n",
    "val_datasets = JobUserDataset(val_job_tensor, val_user_tensor, val_x_tensor, val_y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c8dd805-59f5-4020-ae70-980a4c5cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_datasets, \"train_4.dataset\")\n",
    "torch.save(test_datasets, \"test4.dataset\")\n",
    "torch.save(val_datasets, \"val_4.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03cc9ccd-ffcc-4ec1-8d53-c51d7adb9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, latent_dim, fea_num):\n",
    "        \"\"\"\n",
    "        latent_dim:各个离散特征隐向量的维度\n",
    "        fea_num:特征个数\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        # print('fea_num',fea_num)   #82\n",
    "        #定义三个矩阵，一个是全局偏置，一个是一阶权重矩阵，一个是二阶交叉矩阵\n",
    "        self.w0 = nn.Parameter(torch.zeros([1,]))\n",
    "        self.w1 = nn.Parameter(torch.rand([fea_num, 1]))\n",
    "        self.w2 = nn.Parameter(torch.rand([fea_num, latent_dim]))\n",
    "    def forward(self, x):\n",
    "        #x的维度是(batch_size, fea_num)\n",
    "        #一阶交叉\n",
    "        # x=x[:,:82]   #[32,222]\n",
    "        # print(\"x\",x.shape)\n",
    "        first_order = self.w0 + torch.mm(x, self.w1) #(batch_size, 1)\n",
    "        #二阶交叉\n",
    "        second_order = 1/2 * torch.sum(torch.pow(torch.mm(x, self.w2), 2) - torch.mm(torch.pow(x, 2), torch.pow(self.w2, 2)), dim=1, keepdim=True)\n",
    "        return first_order + second_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5515e3-e33e-4d45-8aec-d01eeec52475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        \"\"\"\n",
    "        hidden_units:列表，每个元素表示每一层的神经单元个数，比如[256,128,64]两层网络，第一个维度是输入维度\n",
    "        \"\"\"\n",
    "        super(Dnn, self).__init__()\n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        #layer[0]: (128,64)   layer[1]:(64,32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        for linear in self.dnn_network:\n",
    "            # print(\"linear\",linear)\n",
    "            # print(\"x1\",x.shape)  # [32,102]\n",
    "            x = linear(x)\n",
    "            # print(\"x2\",x.shape)\n",
    "            x = F.relu(x)\n",
    "            # print(\"x2\", x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print(x,x.shape)   [32,32]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2200344f-0ead-4206-85b2-700ea06d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.):\n",
    "        \"\"\"\n",
    "        feature_columns:特征信息\n",
    "        hidden_units:dnn的隐藏单元个数\n",
    "        dnn_dropout:失活率\n",
    "        \"\"\"\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        print(self.sparse_feature_cols)\n",
    "\n",
    "        # embedding\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for\n",
    "            i, feat in enumerate(self.sparse_feature_cols)    #len=26\n",
    "        })\n",
    "\n",
    "        self.fea_num = len(self.dense_feature_cols)\n",
    "        for one in self.sparse_feature_cols:\n",
    "            self.fea_num += one[\"embed_dim\"]\n",
    "        self.fea_num += len(vec_feas)\n",
    "        hidden_units.insert(0, self.fea_num)  #在hidden_units的最前面插入self.fea_num\n",
    "\n",
    "        self.fm = FM(self.sparse_feature_cols[0]['embed_dim'], self.fea_num)\n",
    "        self.dnn_network = Dnn(hidden_units, dnn_dropout)\n",
    "        self.nn_final_linear = nn.Linear(hidden_units[-1], 1)  #[32,1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs= x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):len(self.dense_feature_cols) + 15]\n",
    "        vec_inputs=x[:,len(self.dense_feature_cols) + 15:]\n",
    "        sparse_inputs = sparse_inputs.long()     #将数字或字符串转换成长整型\n",
    "        sparse_embeds = [self.embed_layers['embed_' + str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]     #for i in range(10)   0-9\n",
    "        sparse_embeds = torch.cat(sparse_embeds, dim=-1)\n",
    "\n",
    "        # 把离散特征、连续特征、文本向量 拼接作为FM和DNN的输入\n",
    "        x = torch.cat([sparse_embeds, dense_inputs, vec_inputs], dim=-1)\n",
    "        # Wide\n",
    "        wide_outputs = self.fm(x)\n",
    "        # deep\n",
    "        deep_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "\n",
    "        # 模型的最后输出\n",
    "        outputs = torch.add(wide_outputs, deep_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f00e7c-2f5b-4117-8488-1618f9959704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobUserDataset(data.Dataset):\n",
    "    '''\n",
    "    Expected data shape like:(data_num, data_len)\n",
    "    '''\n",
    "    def __init__(self, job, user, deepfm, label):\n",
    "        self.job = job\n",
    "        self.user = user\n",
    "        self.deepfm = deepfm\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is None:\n",
    "            return self.job[idx], self.user[idx], self.deepfm[idx]\n",
    "        return self.job[idx], self.user[idx], self.deepfm[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "219e9f1f-2141-42f1-809d-4932c09ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1905f706-7607-40af-afc1-0af87fca0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim, 1, bias=False),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (N, L, D)\n",
    "        a = self.attn(x)        # (N, L, 1)\n",
    "        x = (x * a).sum(dim=1)  # (N, D)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32a06d0-77e2-4d5e-826f-9a7938eddcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_layer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = SelfAttentionEncoder(dim) # * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = self.attn(x)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a7ae0c-28ca-41d5-bfce-7dc3aa9fdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAttentionEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(dim, dim, bias=False)\n",
    "        self.U = nn.Linear(dim, dim, bias=False)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim, 1, bias=False),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        # (N, L, D), (N, S1, D)\n",
    "        s = s.permute(1, 0, 2)  # (S2, N, D)\n",
    "        # calculate co-attention score\n",
    "        y = torch.cat([self.attn(self.W(x.permute(1, 0, 2)) + self.U( _.expand(x.shape[1], _.shape[0], _.shape[1]) ) ).permute(2, 0, 1) for _ in s ]).permute(2, 0, 1)\n",
    "        # (N, D) -> (L, N, D) -> (L, N, 1) -- softmax as L --> (L, N, 1) -> (1, L, N) -> (S2, L, N) -> (N, S2, L)\n",
    "        sr = torch.cat([torch.mm(y[i], _).unsqueeze(0) for i, _ in enumerate(x)])   # (N, S2, D)\n",
    "        sr = torch.sum(sr, dim=1)  # (N, D)\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f8f634b-7d6f-40fb-b43b-e41405d7207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAttention_layer(nn.Module):\n",
    "    def __init__(self, dim, hd_size):\n",
    "        super().__init__()\n",
    "        self.co_attn = CoAttentionEncoder(dim)\n",
    "        self.biLSTM = nn.LSTM(\n",
    "            input_size=dim,\n",
    "            hidden_size=hd_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.self_attn = SelfAttentionEncoder(dim) # * 2\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        # x: self\n",
    "        # s: other\n",
    "        # (N, S1, D), (N, S2, D)\n",
    "        s = s.unsqueeze(2)\n",
    "        s = s.permute(1, 0, 2, 3)  # (S2, N, L, D)\n",
    "        sr = torch.cat([self.co_attn(x, _).unsqueeze(0) for _ in s])   # (S1, N, D)\n",
    "        c = sr.permute(1, 0, 2)     # (N, S1, D)\n",
    "        # c = self.biLSTM(u)[0]       # (N, S1, D)\n",
    "        g = self.self_attn(c)       # (N, D)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2102e626-3641-4144-a640-988da5e39eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APJFFF_text(nn.Module):\n",
    "    def __init__(self, lstm_dim, lstm_hd_size, num_lstm_layers, dropout): #, dropout\n",
    "        super(APJFFF_text, self).__init__()\n",
    "        '''\n",
    "        APJFFF setting\n",
    "        '''\n",
    "        self.user_biLSTM = nn.LSTM(\n",
    "            input_size=lstm_dim,\n",
    "            hidden_size=lstm_hd_size,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.job_biLSTM = nn.LSTM(\n",
    "            input_size=lstm_dim,\n",
    "            hidden_size=lstm_hd_size,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.job_layer_1 = Attention_layer(lstm_hd_size * 2) #, lstm_hd_size\n",
    "        self.job_layer_2 = CoAttention_layer(lstm_hd_size * 2, lstm_hd_size)\n",
    "\n",
    "        self.user_layer_1 = Attention_layer(lstm_hd_size * 2 ) #, lstm_hd_size\n",
    "        self.user_layer_2 = CoAttention_layer(lstm_hd_size * 2 , lstm_hd_size)\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_size=lstm_hd_size * 2 * 8,\n",
    "            output_size=1,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.liner_layer = nn.Linear(lstm_hd_size * 2 * 8, 1)\n",
    "        # self.pool_layer = nn.AdaptiveAvgPool2d((1))\n",
    "\n",
    "    def forward(self, job, user):\n",
    "        # print('usersize',user.size()) # torch.Size([128, 10, 768])\n",
    "\n",
    "        # LSTM part\n",
    "        user_vecs = self.user_biLSTM(user)[0] #.unsqueeze(2)\n",
    "        # print('usersize', user_vecs.size()) # torch.Size([128, 1, 10, 128])\n",
    "        job_vecs = self.job_biLSTM(job)[0] #.unsqueeze(2)\n",
    "\n",
    "        # attention part: bilstm + attention\n",
    "        gj = self.job_layer_1(job_vecs)\n",
    "        gr = self.user_layer_1(user_vecs)\n",
    "\n",
    "        # coAttention part\n",
    "        gjj = self.job_layer_2(job_vecs,user_vecs)\n",
    "        grr = self.user_layer_2(user_vecs, job_vecs)\n",
    "\n",
    "        # concat the vectors\n",
    "        x = torch.cat([gjj, grr, gjj - grr, gjj * grr, gj , gr, gj - gr, gj * gr], axis=1)\n",
    "        # print('x_size1:', x.size()) # x_size1: torch.Size([128, 1024])\n",
    "\n",
    "        # fully connected layer\n",
    "        # x = self.liner_layer(x)\n",
    "        \n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbf39f9f-2467-46ea-a040-bdcb6000c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APJFF_connect(nn.Module):\n",
    "    def __init__(self, lstm_dim, lstm_hd_size, num_lstm_layers, vec_size_2, dropout, feature_columns, hidden_units, dnn_dropout):\n",
    "        super(APJFF_connect, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_size=1, # 2049\n",
    "            output_size=1,\n",
    "            dropout= 0.7 #dropout\n",
    "        )\n",
    "        self.atten_layer = Attention_layer(1)\n",
    "        self.linear_layer = nn.Linear(2,1)\n",
    "        self.text_layer = APJFFF_text(lstm_dim, lstm_hd_size, num_lstm_layers, dropout)\n",
    "        self.entity_layer = DeepFM(feature_columns, hidden_units, dnn_dropout)\n",
    "\n",
    "    def forward(self, job, user, x):\n",
    "        text_vec = self.text_layer(job, user)\n",
    "        entity_vec = self.entity_layer(x)\n",
    "\n",
    "        # attention\n",
    "        vec = torch.stack([text_vec, entity_vec]) # (N, S, D) -> (N, D)\n",
    "        vec = vec.permute(1, 0, 2) # 2, 1, 0, 3\n",
    "        vec_att = self.atten_layer(vec)\n",
    "        x = self.mlp(vec_att)\n",
    "        x = x.squeeze(1)\n",
    "        # x = F.sigmoid(vec_att).squeeze()\n",
    "\n",
    "        # no attention\n",
    "        # vec = entity_vec\n",
    "        # vec = torch.cat([text_vec,entity_vec], axis=1)\n",
    "        # print('vecsize',vec.size())\n",
    "        # x = self.mlp(vec).squeeze(1)\n",
    "        # x = F.sigmoid(vec).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27d9a7d5-fac5-41ed-920e-9f789daecbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(n_epoch, lr, train, valid, model, device, model_name, model_dir=\"./\"):\n",
    "    # summary model parameters\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"\\nstart training, total parameter:{}, trainable:{}\\n\".format(total, trainable))\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    t_batch = len(train)\n",
    "    v_batch = len(valid)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epoch, eta_min=0, last_epoch=-1)\n",
    "    # total_loss, total_acc = 0, 0\n",
    "    best_acc, best_precision, best_recall, best_f1, best_auc = 0, 0, 0, 0, 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        start_time = time.time()\n",
    "        total_loss, total_acc = 0, 0\n",
    "        pred_label = []\n",
    "        y_label = []\n",
    "        # training\n",
    "        for i, (jobs, users, entities, labels) in enumerate(train):\n",
    "\n",
    "            # 放GPU上运行\n",
    "            jobs = jobs.to(torch.float32)\n",
    "            jobs = jobs.to(device)\n",
    "\n",
    "            users = users.to(torch.float32)\n",
    "            users = users.to(device)\n",
    "\n",
    "            entities = entities.to(torch.float32)\n",
    "            entities = entities.to(device)\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # TODO 是否考虑模型用多个优化器？\n",
    "            optimizer.zero_grad() # 将所有模型参数的梯度置为0\n",
    "            # model.zero_grad() # 除所有可训练的torch.Tensor的梯度\n",
    "            outputs = model(jobs, users, entities)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pred_label.extend([0 if i<0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "        train_losses = total_loss/t_batch\n",
    "        train_acc = accuracy_score(y_label, pred_label)\n",
    "        train_precision = precision_score(y_label, pred_label)\n",
    "        train_recall = recall_score(y_label, pred_label)\n",
    "        train_auc = roc_auc_score(y_label, pred_label)\n",
    "        train_f1 = f1_score(y_label, pred_label)\n",
    "        print('[ Epoch{}: {}/{}] '.format(epoch+1, i+1, t_batch))\n",
    "        # print('\\nTrain | Loss:{:.5f} ACC:{:.5f} Precision:{:.5f} Recall:{:.5f} AUC:{:.5f} F1:{:.5f} Time:{:.6f}'.format(train_losses,train_acc,train_precision, train_recall,train_auc,train_f1, time.time()-start_time))\n",
    "\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # pred_score = []\n",
    "            pred_label = []\n",
    "            y_label = []\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for i, (jobs, users, entities, labels) in enumerate(valid):\n",
    "                # 放GPU上运行\n",
    "                jobs = jobs.to(torch.float32)\n",
    "                jobs = jobs.to(device)\n",
    "\n",
    "                users = users.to(torch.float32)\n",
    "                users = users.to(device)\n",
    "\n",
    "                entities = entities.to(torch.float32)\n",
    "                entities = entities.to(device)\n",
    "\n",
    "                labels = labels.to(torch.float32)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(jobs, users, entities)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                '''\n",
    "                存一下预测score\n",
    "                '''\n",
    "                # pred_score.extend([j for j in list(outputs.cpu().detach().numpy())])\n",
    "                pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "                y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "            val_losses = total_loss/v_batch\n",
    "            val_acc = accuracy_score(y_label, pred_label)\n",
    "            val_precision = precision_score(y_label, pred_label)\n",
    "            val_recall = recall_score(y_label, pred_label)\n",
    "            val_auc = roc_auc_score(y_label, pred_label)\n",
    "            val_f1 = f1_score(y_label, pred_label)\n",
    "            print('\\nVal | Loss:{:.5f} ACC:{:.5f} Precision:{:.5f} Recall:{:.5f} AUC:{:.5f} F1:{:.5f} Time:{:.6f}'.format(val_losses,val_acc,val_precision, val_recall,val_auc,val_f1, time.time()-start_time))\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_precision = val_precision\n",
    "                best_recall = val_recall\n",
    "                best_f1 = val_f1\n",
    "                best_auc = val_auc\n",
    "                torch.save(model, \"{}/{}.model\".format(model_dir, model_name))\n",
    "                print('save model with acc: {:.3f}, recall: {:.3f}, auc: {:.3f}'.format(best_acc,best_recall,best_auc))\n",
    "        print('------------------------------------------------------')\n",
    "        lr_scheduler.step()\n",
    "        model.train()\n",
    "    return best_acc, best_precision, best_recall, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6f5931-a2ac-44a7-9d73-d83c8064217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型参数\n",
    "hidden_units = [128, 64, 32]\n",
    "dnn_dropout = 0.7\n",
    "\n",
    "\n",
    "lstm_dim = 32 #512 #768\n",
    "lstm_hd_size = 128\n",
    "num_lstm_layers = 1\n",
    "dropout = 0.7\n",
    "vec_size_2 = 32\n",
    "\n",
    "# 训练参数\n",
    "epoch = 30\n",
    "lr = 0.005\n",
    "# batch_size = 4012\n",
    "batch_size = 32\n",
    "model_dir = './' # change with your model save path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"APJFFF_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0086944-9fe6-40e8-abfc-56f889f02c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'feat': 'UserID', 'feat_num': 7921, 'embed_dim': 8}, {'feat': '性别', 'feat_num': 2, 'embed_dim': 8}, {'feat': '专业', 'feat_num': 935, 'embed_dim': 8}, {'feat': 'JobID', 'feat_num': 31647, 'embed_dim': 8}, {'feat': '企业融资阶段', 'feat_num': 9, 'embed_dim': 8}, {'feat': '企业人员规模', 'feat_num': 7, 'embed_dim': 8}, {'feat': '企业休息时间', 'feat_num': 4, 'embed_dim': 8}, {'feat': '企业加班情况', 'feat_num': 3, 'embed_dim': 8}, {'feat': '岗位一级类别', 'feat_num': 21, 'embed_dim': 8}, {'feat': '岗位三级类别', 'feat_num': 530, 'embed_dim': 8}, {'feat': '岗位工作经验', 'feat_num': 5, 'embed_dim': 8}, {'feat': '岗位招聘类型', 'feat_num': 4, 'embed_dim': 8}, {'feat': 'match_degree', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'match_loc_job', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'match_loc_corp', 'feat_num': 2, 'embed_dim': 8}]\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "APJFFF_model = APJFF_connect(lstm_dim, lstm_hd_size, num_lstm_layers, vec_size_2, dropout, feature_columns, hidden_units, dnn_dropout)\n",
    "\n",
    "train_dataset = torch.load(\"train_4.dataset\")\n",
    "val_dataset = torch.load(\"val_4.dataset\")\n",
    "test_dataset = torch.load(\"test4.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3f08e0c-12c4-4a6a-a019-7099b7edb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader导入\n",
    "train_loader = DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0040c4b-db50-4859-a1b1-49872f6d170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APJFFF_model = torch.load('APJFFF.model') #, map_location=device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8481161e-6e4a-40fb-b003-1d8585310ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training, total parameter:6208179, trainable:6208179\n",
      "\n",
      "[ Epoch1: 1766/1766] \n",
      "\n",
      "Val | Loss:0.69321 ACC:0.50273 Precision:0.50273 Recall:1.00000 AUC:0.50000 F1:0.66909 Time:203.828485\n",
      "save model with acc: 0.503, recall: 1.000, auc: 0.500\n",
      "------------------------------------------------------\n",
      "[ Epoch2: 1766/1766] \n",
      "\n",
      "Val | Loss:0.69311 ACC:0.50279 Precision:0.50276 Recall:0.99937 AUC:0.50006 F1:0.66898 Time:203.183672\n",
      "save model with acc: 0.503, recall: 0.999, auc: 0.500\n",
      "------------------------------------------------------\n",
      "[ Epoch3: 1766/1766] \n",
      "\n",
      "Val | Loss:0.69335 ACC:0.49727 Precision:0.00000 Recall:0.00000 AUC:0.50000 F1:0.00000 Time:204.951444\n",
      "------------------------------------------------------\n",
      "[ Epoch4: 1766/1766] \n",
      "\n",
      "Val | Loss:0.69318 ACC:0.50279 Precision:0.50276 Recall:1.00000 AUC:0.50005 F1:0.66912 Time:206.270459\n",
      "------------------------------------------------------\n",
      "[ Epoch5: 1766/1766] \n",
      "\n",
      "Val | Loss:0.68280 ACC:0.58868 Precision:0.55134 Recall:0.97645 AUC:0.58655 F1:0.70475 Time:203.727697\n",
      "save model with acc: 0.589, recall: 0.976, auc: 0.587\n",
      "------------------------------------------------------\n",
      "[ Epoch6: 1766/1766] \n",
      "\n",
      "Val | Loss:0.64474 ACC:0.67702 Precision:0.62079 Recall:0.91880 AUC:0.67569 F1:0.74095 Time:203.843395\n",
      "save model with acc: 0.677, recall: 0.919, auc: 0.676\n",
      "------------------------------------------------------\n",
      "[ Epoch7: 1766/1766] \n",
      "\n",
      "Val | Loss:0.60274 ACC:0.69714 Precision:0.74930 Recall:0.59747 AUC:0.69769 F1:0.66483 Time:201.025705\n",
      "save model with acc: 0.697, recall: 0.597, auc: 0.698\n",
      "------------------------------------------------------\n",
      "[ Epoch8: 1766/1766] \n",
      "\n",
      "Val | Loss:0.57511 ACC:0.72750 Precision:0.81323 Recall:0.59451 AUC:0.72824 F1:0.68688 Time:202.367469\n",
      "save model with acc: 0.728, recall: 0.595, auc: 0.728\n",
      "------------------------------------------------------\n",
      "[ Epoch9: 1766/1766] \n",
      "\n",
      "Val | Loss:0.52548 ACC:0.78309 Precision:0.76893 Recall:0.81278 AUC:0.78292 F1:0.79025 Time:202.936190\n",
      "save model with acc: 0.783, recall: 0.813, auc: 0.783\n",
      "------------------------------------------------------\n",
      "[ Epoch10: 1766/1766] \n",
      "\n",
      "Val | Loss:0.50537 ACC:0.79439 Precision:0.81870 Recall:0.75913 AUC:0.79459 F1:0.78779 Time:203.151037\n",
      "save model with acc: 0.794, recall: 0.759, auc: 0.795\n",
      "------------------------------------------------------\n",
      "[ Epoch11: 1766/1766] \n",
      "\n",
      "Val | Loss:0.50865 ACC:0.79530 Precision:0.76970 Recall:0.84593 AUC:0.79502 F1:0.80602 Time:202.008505\n",
      "save model with acc: 0.795, recall: 0.846, auc: 0.795\n",
      "------------------------------------------------------\n",
      "[ Epoch12: 1766/1766] \n",
      "\n",
      "Val | Loss:0.47334 ACC:0.80437 Precision:0.81112 Recall:0.79630 AUC:0.80442 F1:0.80364 Time:205.280066\n",
      "save model with acc: 0.804, recall: 0.796, auc: 0.804\n",
      "------------------------------------------------------\n",
      "[ Epoch13: 1766/1766] \n",
      "\n",
      "Val | Loss:0.46994 ACC:0.80618 Precision:0.80222 Recall:0.81552 AUC:0.80613 F1:0.80882 Time:206.526592\n",
      "save model with acc: 0.806, recall: 0.816, auc: 0.806\n",
      "------------------------------------------------------\n",
      "[ Epoch14: 1766/1766] \n",
      "\n",
      "Val | Loss:0.51573 ACC:0.80963 Precision:0.81985 Recall:0.79630 AUC:0.80970 F1:0.80791 Time:207.476254\n",
      "save model with acc: 0.810, recall: 0.796, auc: 0.810\n",
      "------------------------------------------------------\n",
      "[ Epoch15: 1766/1766] \n",
      "\n",
      "Val | Loss:0.46667 ACC:0.81228 Precision:0.80437 Recall:0.82798 AUC:0.81220 F1:0.81601 Time:208.971838\n",
      "save model with acc: 0.812, recall: 0.828, auc: 0.812\n",
      "------------------------------------------------------\n",
      "[ Epoch16: 1766/1766] \n",
      "\n",
      "Val | Loss:0.48119 ACC:0.80990 Precision:0.79721 Recall:0.83400 AUC:0.80976 F1:0.81519 Time:204.931581\n",
      "------------------------------------------------------\n",
      "[ Epoch17: 1766/1766] \n",
      "\n",
      "Val | Loss:0.45538 ACC:0.81292 Precision:0.80134 Recall:0.83485 AUC:0.81280 F1:0.81775 Time:203.314876\n",
      "save model with acc: 0.813, recall: 0.835, auc: 0.813\n",
      "------------------------------------------------------\n",
      "[ Epoch18: 1766/1766] \n",
      "\n",
      "Val | Loss:0.47917 ACC:0.81568 Precision:0.81897 Recall:0.81309 AUC:0.81570 F1:0.81602 Time:205.360566\n",
      "save model with acc: 0.816, recall: 0.813, auc: 0.816\n",
      "------------------------------------------------------\n",
      "[ Epoch19: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43743 ACC:0.81823 Precision:0.81949 Recall:0.81880 AUC:0.81823 F1:0.81914 Time:214.758178\n",
      "save model with acc: 0.818, recall: 0.819, auc: 0.818\n",
      "------------------------------------------------------\n",
      "[ Epoch20: 1766/1766] \n",
      "\n",
      "Val | Loss:0.45430 ACC:0.81271 Precision:0.78867 Recall:0.85713 AUC:0.81246 F1:0.82148 Time:208.028501\n",
      "------------------------------------------------------\n",
      "[ Epoch21: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43343 ACC:0.82131 Precision:0.79933 Recall:0.86061 AUC:0.82109 F1:0.82884 Time:205.505942\n",
      "save model with acc: 0.821, recall: 0.861, auc: 0.821\n",
      "------------------------------------------------------\n",
      "[ Epoch22: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41838 ACC:0.82471 Precision:0.82774 Recall:0.82249 AUC:0.82472 F1:0.82511 Time:210.815157\n",
      "save model with acc: 0.825, recall: 0.822, auc: 0.825\n",
      "------------------------------------------------------\n",
      "[ Epoch23: 1766/1766] \n",
      "\n",
      "Val | Loss:0.42757 ACC:0.82311 Precision:0.80782 Recall:0.85048 AUC:0.82296 F1:0.82860 Time:202.535733\n",
      "------------------------------------------------------\n",
      "[ Epoch24: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41205 ACC:0.82609 Precision:0.82416 Recall:0.83147 AUC:0.82606 F1:0.82780 Time:196.131270\n",
      "save model with acc: 0.826, recall: 0.831, auc: 0.826\n",
      "------------------------------------------------------\n",
      "[ Epoch25: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41428 ACC:0.82497 Precision:0.82986 Recall:0.81996 AUC:0.82500 F1:0.82488 Time:196.150639\n",
      "------------------------------------------------------\n",
      "[ Epoch26: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40971 ACC:0.82471 Precision:0.81361 Recall:0.84488 AUC:0.82460 F1:0.82895 Time:194.707675\n",
      "------------------------------------------------------\n",
      "[ Epoch27: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40628 ACC:0.82529 Precision:0.81606 Recall:0.84234 AUC:0.82520 F1:0.82899 Time:195.590300\n",
      "------------------------------------------------------\n",
      "[ Epoch28: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40778 ACC:0.82460 Precision:0.81408 Recall:0.84382 AUC:0.82449 F1:0.82868 Time:194.961080\n",
      "------------------------------------------------------\n",
      "[ Epoch29: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40761 ACC:0.82396 Precision:0.81417 Recall:0.84203 AUC:0.82386 F1:0.82787 Time:195.019989\n",
      "------------------------------------------------------\n",
      "[ Epoch30: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40841 ACC:0.82295 Precision:0.81082 Recall:0.84498 AUC:0.82283 F1:0.82755 Time:195.607301\n",
      "------------------------------------------------------\n",
      "best_acc 0.8260869565217391\n",
      "best_precision 0.8241574209755076\n",
      "best_recall 0.8241574209755076\n",
      "best_f1 0.8277964676198485\n",
      "best_auc 0.8260573725481928\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "best_acc, best_precision, best_recall, best_f1, best_auc = training(epoch, lr, train_loader, val_loader, APJFFF_model, device, model_name, model_dir)\n",
    "\n",
    "# 输出结果（验证集）\n",
    "print('best_acc',best_acc)\n",
    "print('best_precision',best_precision)\n",
    "print('best_recall',best_precision)\n",
    "print('best_f1',best_f1)\n",
    "print('best_auc',best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33a4cc60-f49b-47bf-b856-749ae71b9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_loader):\n",
    "    pred_label = []\n",
    "    y_label = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (jobs, users, entities, labels) in enumerate(test_loader):\n",
    "            # 放GPU上运行\n",
    "            jobs = jobs.to(torch.float32)\n",
    "            jobs = jobs.to(device)\n",
    "\n",
    "            users = users.to(torch.float32)\n",
    "            users = users.to(device)\n",
    "\n",
    "            entities = entities.to(torch.float32)\n",
    "            entities = entities.to(device)\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(jobs, users, entities)\n",
    "\n",
    "            pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "\n",
    "        test_acc = accuracy_score(y_label, pred_label)\n",
    "        test_precision = precision_score(y_label, pred_label)\n",
    "        test_recall = recall_score(y_label, pred_label)\n",
    "        test_auc = roc_auc_score(y_label, pred_label)\n",
    "        test_f1 = f1_score(y_label, pred_label)\n",
    "    return test_acc, test_auc, test_precision, test_recall, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ed8cc2b-4e8c-4c73-b930-465fecf056e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.8226893879067793\n",
      "test_precision 0.8180574555403557\n",
      "test_recall 0.8180574555403557\n",
      "test_f1 0.8231681490893689\n",
      "test_auc 0.8227094259281847\n"
     ]
    }
   ],
   "source": [
    "# 输出结果(测试集)\n",
    "test_acc, test_auc, test_precision, test_recall, test_f1 = testing(\n",
    "    torch.load('APJFFF_bert.model'), test_loader)\n",
    "print('test_acc', test_acc)\n",
    "print('test_precision', test_precision)\n",
    "print('test_recall', test_precision)\n",
    "print('test_f1', test_f1)\n",
    "print('test_auc', test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
