{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb28321-238b-4db2-b4ef-c36dc08ec153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "import datetime\n",
    "import time\n",
    "from transformers import BertConfig, BertModel, BertTokenizer, BertForMaskedLM\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import word2vec, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad166e6-d167-471d-914e-2959eb3db314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 设置随机数种子\n",
    "setup_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ddf018-af0f-46bf-b4e3-aff355a1a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/root/autodl-fs/dataset/dataset_user_job_all_test1.csv', dtype = {'UserID': 'str', 'JobID': 'str','label': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7194e91-187f-4cf1-91cf-a886a5d46521",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_job = dataset['skill_entity_en_job'].values\n",
    "skill_user = dataset['skill_entity_en_user'].values\n",
    "\n",
    "skill_job_emb = []\n",
    "for skills in skill_job:\n",
    "    skill_job_emb.append(skills.split(','))\n",
    "dataset['skill_job'] = skill_job_emb\n",
    "\n",
    "skill_user_emb = []\n",
    "for skills in skill_user:\n",
    "    skill_user_emb.append(skills.split(','))\n",
    "dataset['skill_user'] = skill_user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeddd2d0-e037-4adf-a7de-1a4a0a0061e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_array = np.concatenate((skill_job_emb,skill_user_emb),axis=0)\n",
    "# w2v_model = word2vec.Word2Vec(text_array, size=100, window=5, min_count=2, workers=8, iter=10, sg=1)\n",
    "w2v_model = word2vec.Word2Vec(text_array, size=8, window=5, min_count=2, workers=8, iter=10, sg=1)\n",
    "w2v_model.save('word2vec_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6261cdc7-f7b9-438d-8726-0eb1084b9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec_all.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ffe314b-5cf7-4406-82e8-684b22e85778",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_present_list = list(w2v_model.wv.index2word)\n",
    "dataset['skill_job'] = dataset['skill_job'].apply(lambda x:[i for i in x if i in word_present_list])\n",
    "dataset['skill_user'] = dataset['skill_user'].apply(lambda x:[i for i in x if i in word_present_list])\n",
    "# 先用列平均值，后面看情况再改\n",
    "dataset['skill_job'] = dataset['skill_job'].apply(lambda x: np.mean([np.array(w2v_model.wv[i]).reshape(1,8) for i in x], axis=0))\n",
    "dataset['skill_user'] = dataset['skill_user'].apply(lambda x: np.mean([np.array(w2v_model.wv[i]).reshape(1,8) for i in x], axis=0))\n",
    "\n",
    "skill_user_1 = []\n",
    "skill_user_2 = []\n",
    "skill_user_3 = []\n",
    "skill_user_4 = []\n",
    "skill_user_5 = []\n",
    "skill_user_6 = []\n",
    "skill_user_7 = []\n",
    "skill_user_8 = []\n",
    "\n",
    "skill_job_1 = []\n",
    "skill_job_2 = []\n",
    "skill_job_3 = []\n",
    "skill_job_4 = []\n",
    "skill_job_5 = []\n",
    "skill_job_6 = []\n",
    "skill_job_7 = []\n",
    "skill_job_8 = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    try:\n",
    "        skill_job_embedding = dataset.loc[i, 'skill_job'][0].tolist()\n",
    "        skill_job_1.append(skill_job_embedding[0])\n",
    "        skill_job_2.append(skill_job_embedding[1])\n",
    "        skill_job_3.append(skill_job_embedding[2])\n",
    "        skill_job_4.append(skill_job_embedding[3])\n",
    "        skill_job_5.append(skill_job_embedding[4])\n",
    "        skill_job_6.append(skill_job_embedding[5])\n",
    "        skill_job_7.append(skill_job_embedding[6])\n",
    "        skill_job_8.append(skill_job_embedding[7])\n",
    "    except:\n",
    "        skill_job_1.append(0)\n",
    "        skill_job_2.append(0)\n",
    "        skill_job_3.append(0)\n",
    "        skill_job_4.append(0)\n",
    "        skill_job_5.append(0)\n",
    "        skill_job_6.append(0)\n",
    "        skill_job_7.append(0)\n",
    "        skill_job_8.append(0)\n",
    "    skill_user_embedding = dataset.loc[i, 'skill_user'][0].tolist()\n",
    "    skill_user_1.append(skill_user_embedding[0])\n",
    "    skill_user_2.append(skill_user_embedding[1])\n",
    "    skill_user_3.append(skill_user_embedding[2])\n",
    "    skill_user_4.append(skill_user_embedding[3])\n",
    "    skill_user_5.append(skill_user_embedding[4])\n",
    "    skill_user_6.append(skill_user_embedding[5])\n",
    "    skill_user_7.append(skill_user_embedding[6])\n",
    "    skill_user_8.append(skill_user_embedding[7])\n",
    "\n",
    "\n",
    "dataset['skill_user_1'] = skill_user_1\n",
    "dataset['skill_user_2'] = skill_user_2\n",
    "dataset['skill_user_3'] = skill_user_3\n",
    "dataset['skill_user_4'] = skill_user_4\n",
    "dataset['skill_user_5'] = skill_user_5\n",
    "dataset['skill_user_6'] = skill_user_6\n",
    "dataset['skill_user_7'] = skill_user_7\n",
    "dataset['skill_user_8'] = skill_user_8\n",
    "\n",
    "dataset['skill_job_1'] = skill_job_1\n",
    "dataset['skill_job_2'] = skill_job_2\n",
    "dataset['skill_job_3'] = skill_job_3\n",
    "dataset['skill_job_4'] = skill_job_4\n",
    "dataset['skill_job_5'] = skill_job_5\n",
    "dataset['skill_job_6'] = skill_job_6\n",
    "dataset['skill_job_7'] = skill_job_7\n",
    "dataset['skill_job_8'] = skill_job_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb9726d-bf7d-4161-987b-2f23706b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 稠密特征\n",
    "dense_feas = ['岗位薪资下限(K)','岗位薪资上限(K)','work_length','总分','岗位招聘人数']\n",
    "\n",
    "# 文本特征\n",
    "vec_feas = ['skill_job_1','skill_job_2','skill_job_3','skill_job_4',\n",
    "            'skill_job_5','skill_job_6','skill_job_7','skill_job_8',\n",
    "            'skill_user_1','skill_user_2','skill_user_3','skill_user_4',\n",
    "            'skill_user_5','skill_user_6','skill_user_7','skill_user_8']\n",
    "\n",
    "text_feas = ['岗位名称', '岗位描述', 'experience']\n",
    "\n",
    "# 稀疏特征\n",
    "## TODO userid jobid应该放进去吗\n",
    "sparse_feas_user = ['UserID','性别','专业']\n",
    "sparse_feas_job = ['JobID','企业融资阶段','企业人员规模','企业休息时间','企业加班情况','岗位一级类别','岗位三级类别','岗位工作经验','岗位招聘类型'] # '岗位二级类别'\n",
    "sparse_feas_match = ['match_degree','match_loc_job','match_loc_corp']\n",
    "sparse_feas = sparse_feas_user + sparse_feas_job + sparse_feas_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a216ad15-c327-481a-9221-17acdd5f5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseFeature(feat, feat_num, embed_dim=8):\n",
    "    # if len(dataset[feat].unique()) < embed_dim:\n",
    "    #     embed_dim = len(dataset[feat].unique())\n",
    "    return {'feat':feat, 'feat_num':feat_num, 'embed_dim':embed_dim}\n",
    "\n",
    "def denseFeature(feat):\n",
    "    return {'feat':feat}\n",
    "\n",
    "def vecFeature(feat):\n",
    "    return{'feat':feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c8c94ee-5164-41c9-995a-1be525d8fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 8\n",
    "feature_columns = [[denseFeature(feat) for feat in dense_feas]] +[[sparseFeature(feat, len(dataset[feat].unique()), embed_dim=embed_dim) for feat in sparse_feas]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cc9ccd-ffcc-4ec1-8d53-c51d7adb9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, latent_dim, fea_num):\n",
    "        \"\"\"\n",
    "        latent_dim:各个离散特征隐向量的维度\n",
    "        fea_num:特征个数\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        # print('fea_num',fea_num)   #82\n",
    "        #定义三个矩阵，一个是全局偏置，一个是一阶权重矩阵，一个是二阶交叉矩阵\n",
    "        self.w0 = nn.Parameter(torch.zeros([1,]))\n",
    "        self.w1 = nn.Parameter(torch.rand([fea_num, 1]))\n",
    "        self.w2 = nn.Parameter(torch.rand([fea_num, latent_dim]))\n",
    "    def forward(self, x):\n",
    "        #x的维度是(batch_size, fea_num)\n",
    "        #一阶交叉\n",
    "        # x=x[:,:82]   #[32,222]\n",
    "        # print(\"x\",x.shape)\n",
    "        first_order = self.w0 + torch.mm(x, self.w1) #(batch_size, 1)\n",
    "        #二阶交叉\n",
    "        second_order = 1/2 * torch.sum(torch.pow(torch.mm(x, self.w2), 2) - torch.mm(torch.pow(x, 2), torch.pow(self.w2, 2)), dim=1, keepdim=True)\n",
    "        return first_order + second_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5515e3-e33e-4d45-8aec-d01eeec52475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        \"\"\"\n",
    "        hidden_units:列表，每个元素表示每一层的神经单元个数，比如[256,128,64]两层网络，第一个维度是输入维度\n",
    "        \"\"\"\n",
    "        super(Dnn, self).__init__()\n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        #layer[0]: (128,64)   layer[1]:(64,32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        for linear in self.dnn_network:\n",
    "            # print(\"linear\",linear)\n",
    "            # print(\"x1\",x.shape)  # [32,102]\n",
    "            x = linear(x)\n",
    "            # print(\"x2\",x.shape)\n",
    "            x = F.relu(x)\n",
    "            # print(\"x2\", x.shape)\n",
    "        x = self.dropout(x)\n",
    "        # print(x,x.shape)   [32,32]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2200344f-0ead-4206-85b2-700ea06d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.):\n",
    "        \"\"\"\n",
    "        feature_columns:特征信息\n",
    "        hidden_units:dnn的隐藏单元个数\n",
    "        dnn_dropout:失活率\n",
    "        \"\"\"\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        print(self.sparse_feature_cols)\n",
    "\n",
    "        # embedding\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for\n",
    "            i, feat in enumerate(self.sparse_feature_cols)    #len=26\n",
    "        })\n",
    "\n",
    "        self.fea_num = len(self.dense_feature_cols)\n",
    "        for one in self.sparse_feature_cols:\n",
    "            self.fea_num += one[\"embed_dim\"]\n",
    "        self.fea_num += len(vec_feas)\n",
    "        hidden_units.insert(0, self.fea_num)  #在hidden_units的最前面插入self.fea_num\n",
    "\n",
    "        self.fm = FM(self.sparse_feature_cols[0]['embed_dim'], self.fea_num)\n",
    "        self.dnn_network = Dnn(hidden_units, dnn_dropout)\n",
    "        self.nn_final_linear = nn.Linear(hidden_units[-1], 1)  #[32,1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs= x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):len(self.dense_feature_cols) + 15]\n",
    "        vec_inputs=x[:,len(self.dense_feature_cols) + 15:]\n",
    "        sparse_inputs = sparse_inputs.long()     #将数字或字符串转换成长整型\n",
    "        sparse_embeds = [self.embed_layers['embed_' + str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]     #for i in range(10)   0-9\n",
    "        sparse_embeds = torch.cat(sparse_embeds, dim=-1)\n",
    "\n",
    "        # 把离散特征、连续特征、文本向量 拼接作为FM和DNN的输入\n",
    "        x = torch.cat([sparse_embeds, dense_inputs, vec_inputs], dim=-1)\n",
    "        # Wide\n",
    "        wide_outputs = self.fm(x)\n",
    "        # deep\n",
    "        deep_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "\n",
    "        # 模型的最后输出\n",
    "        outputs = torch.add(wide_outputs, deep_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f00e7c-2f5b-4117-8488-1618f9959704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobUserDataset(data.Dataset):\n",
    "    '''\n",
    "    Expected data shape like:(data_num, data_len)\n",
    "    '''\n",
    "    def __init__(self, job, user, deepfm, label):\n",
    "        self.job = job\n",
    "        self.user = user\n",
    "        self.deepfm = deepfm\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is None:\n",
    "            return self.job[idx], self.user[idx], self.deepfm[idx]\n",
    "        return self.job[idx], self.user[idx], self.deepfm[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219e9f1f-2141-42f1-809d-4932c09ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1905f706-7607-40af-afc1-0af87fca0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim, 1, bias=False),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (N, L, D)\n",
    "        a = self.attn(x)        # (N, L, 1)\n",
    "        x = (x * a).sum(dim=1)  # (N, D)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b32a06d0-77e2-4d5e-826f-9a7938eddcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_layer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = SelfAttentionEncoder(dim) # * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = self.attn(x)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a7ae0c-28ca-41d5-bfce-7dc3aa9fdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAttentionEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(dim, dim, bias=False)\n",
    "        self.U = nn.Linear(dim, dim, bias=False)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(dim, 1, bias=False),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        # (N, L, D), (N, S1, D)\n",
    "        s = s.permute(1, 0, 2)  # (S2, N, D)\n",
    "        # calculate co-attention score\n",
    "        y = torch.cat([self.attn(self.W(x.permute(1, 0, 2)) + self.U( _.expand(x.shape[1], _.shape[0], _.shape[1]) ) ).permute(2, 0, 1) for _ in s ]).permute(2, 0, 1)\n",
    "        # (N, D) -> (L, N, D) -> (L, N, 1) -- softmax as L --> (L, N, 1) -> (1, L, N) -> (S2, L, N) -> (N, S2, L)\n",
    "        sr = torch.cat([torch.mm(y[i], _).unsqueeze(0) for i, _ in enumerate(x)])   # (N, S2, D)\n",
    "        sr = torch.sum(sr, dim=1)  # (N, D)\n",
    "        return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f8f634b-7d6f-40fb-b43b-e41405d7207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAttention_layer(nn.Module):\n",
    "    def __init__(self, dim, hd_size):\n",
    "        super().__init__()\n",
    "        self.co_attn = CoAttentionEncoder(dim)\n",
    "        self.biLSTM = nn.LSTM(\n",
    "            input_size=dim,\n",
    "            hidden_size=hd_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.self_attn = SelfAttentionEncoder(dim) # * 2\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        # x: self\n",
    "        # s: other\n",
    "        # (N, S1, D), (N, S2, D)\n",
    "        s = s.unsqueeze(2)\n",
    "        s = s.permute(1, 0, 2, 3)  # (S2, N, L, D)\n",
    "        sr = torch.cat([self.co_attn(x, _).unsqueeze(0) for _ in s])   # (S1, N, D)\n",
    "        c = sr.permute(1, 0, 2)     # (N, S1, D)\n",
    "        # c = self.biLSTM(u)[0]       # (N, S1, D)\n",
    "        g = self.self_attn(c)       # (N, D)\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2102e626-3641-4144-a640-988da5e39eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APJFFF_text(nn.Module):\n",
    "    def __init__(self, lstm_dim, lstm_hd_size, num_lstm_layers, dropout): #, dropout\n",
    "        super(APJFFF_text, self).__init__()\n",
    "        '''\n",
    "        APJFFF setting\n",
    "        '''\n",
    "        self.user_biLSTM = nn.LSTM(\n",
    "            input_size=lstm_dim,\n",
    "            hidden_size=lstm_hd_size,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.job_biLSTM = nn.LSTM(\n",
    "            input_size=lstm_dim,\n",
    "            hidden_size=lstm_hd_size,\n",
    "            num_layers=num_lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "\n",
    "        self.job_layer_1 = Attention_layer(lstm_hd_size * 2) #, lstm_hd_size\n",
    "        self.job_layer_2 = CoAttention_layer(lstm_hd_size * 2, lstm_hd_size)\n",
    "\n",
    "        self.user_layer_1 = Attention_layer(lstm_hd_size * 2 ) #, lstm_hd_size\n",
    "        self.user_layer_2 = CoAttention_layer(lstm_hd_size * 2 , lstm_hd_size)\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_size=lstm_hd_size * 2 * 8,\n",
    "            output_size=1,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.liner_layer = nn.Linear(lstm_hd_size * 2 * 8, 1)\n",
    "        # self.pool_layer = nn.AdaptiveAvgPool2d((1))\n",
    "\n",
    "    def forward(self, job, user):\n",
    "        # print('usersize',user.size()) # torch.Size([128, 10, 768])\n",
    "\n",
    "        # LSTM part\n",
    "        user_vecs = self.user_biLSTM(user)[0] #.unsqueeze(2)\n",
    "        # print('usersize', user_vecs.size()) # torch.Size([128, 1, 10, 128])\n",
    "        job_vecs = self.job_biLSTM(job)[0] #.unsqueeze(2)\n",
    "\n",
    "        # attention part: bilstm + attention\n",
    "        gj = self.job_layer_1(job_vecs)\n",
    "        gr = self.user_layer_1(user_vecs)\n",
    "\n",
    "        # coAttention part\n",
    "        gjj = self.job_layer_2(job_vecs,user_vecs)\n",
    "        grr = self.user_layer_2(user_vecs, job_vecs)\n",
    "\n",
    "        # concat the vectors\n",
    "        x = torch.cat([gjj, grr, gjj - grr, gjj * grr, gj , gr, gj - gr, gj * gr], axis=1)\n",
    "        # print('x_size1:', x.size()) # x_size1: torch.Size([128, 1024])\n",
    "\n",
    "        # fully connected layer\n",
    "        # x = self.liner_layer(x)\n",
    "        \n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbf39f9f-2467-46ea-a040-bdcb6000c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APJFF_connect(nn.Module):\n",
    "    def __init__(self, lstm_dim, lstm_hd_size, num_lstm_layers, vec_size_2, dropout, feature_columns, hidden_units, dnn_dropout):\n",
    "        super(APJFF_connect, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_size=1, # 2049\n",
    "            output_size=1,\n",
    "            dropout= 0.7 #dropout\n",
    "        )\n",
    "        self.atten_layer = Attention_layer(1)\n",
    "        self.linear_layer = nn.Linear(2,1)\n",
    "        self.text_layer = APJFFF_text(lstm_dim, lstm_hd_size, num_lstm_layers, dropout)\n",
    "        self.entity_layer = DeepFM(feature_columns, hidden_units, dnn_dropout)\n",
    "\n",
    "    def forward(self, job, user, x):\n",
    "        text_vec = self.text_layer(job, user)\n",
    "        entity_vec = self.entity_layer(x)\n",
    "\n",
    "        # attention\n",
    "        vec = torch.stack([text_vec, entity_vec]) # (N, S, D) -> (N, D)\n",
    "        vec = vec.permute(1, 0, 2) # 2, 1, 0, 3\n",
    "        vec_att = self.atten_layer(vec)\n",
    "        x = self.mlp(vec_att)\n",
    "        x = x.squeeze(1)\n",
    "        # x = F.sigmoid(vec_att).squeeze()\n",
    "\n",
    "        # no attention\n",
    "        # vec = entity_vec\n",
    "        # vec = torch.cat([text_vec,entity_vec], axis=1)\n",
    "        # print('vecsize',vec.size())\n",
    "        # x = self.mlp(vec).squeeze(1)\n",
    "        # x = F.sigmoid(vec).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d9a7d5-fac5-41ed-920e-9f789daecbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(n_epoch, lr, train, valid, model, device, model_name, model_dir=\"./\"):\n",
    "    # summary model parameters\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"\\nstart training, total parameter:{}, trainable:{}\\n\".format(total, trainable))\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    t_batch = len(train)\n",
    "    v_batch = len(valid)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epoch, eta_min=0, last_epoch=-1)\n",
    "    # total_loss, total_acc = 0, 0\n",
    "    best_acc, best_precision, best_recall, best_f1, best_auc = 0, 0, 0, 0, 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        start_time = time.time()\n",
    "        total_loss, total_acc = 0, 0\n",
    "        pred_label = []\n",
    "        y_label = []\n",
    "        # training\n",
    "        for i, (jobs, users, entities, labels) in enumerate(train):\n",
    "\n",
    "            # 放GPU上运行\n",
    "            jobs = jobs.to(torch.float32)\n",
    "            jobs = jobs.to(device)\n",
    "\n",
    "            users = users.to(torch.float32)\n",
    "            users = users.to(device)\n",
    "\n",
    "            entities = entities.to(torch.float32)\n",
    "            entities = entities.to(device)\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # TODO 是否考虑模型用多个优化器？\n",
    "            optimizer.zero_grad() # 将所有模型参数的梯度置为0\n",
    "            # model.zero_grad() # 除所有可训练的torch.Tensor的梯度\n",
    "            outputs = model(jobs, users, entities)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pred_label.extend([0 if i<0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "        train_losses = total_loss/t_batch\n",
    "        train_acc = accuracy_score(y_label, pred_label)\n",
    "        train_precision = precision_score(y_label, pred_label)\n",
    "        train_recall = recall_score(y_label, pred_label)\n",
    "        train_auc = roc_auc_score(y_label, pred_label)\n",
    "        train_f1 = f1_score(y_label, pred_label)\n",
    "        print('[ Epoch{}: {}/{}] '.format(epoch+1, i+1, t_batch))\n",
    "        # print('\\nTrain | Loss:{:.5f} ACC:{:.5f} Precision:{:.5f} Recall:{:.5f} AUC:{:.5f} F1:{:.5f} Time:{:.6f}'.format(train_losses,train_acc,train_precision, train_recall,train_auc,train_f1, time.time()-start_time))\n",
    "\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # pred_score = []\n",
    "            pred_label = []\n",
    "            y_label = []\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for i, (jobs, users, entities, labels) in enumerate(valid):\n",
    "                # 放GPU上运行\n",
    "                jobs = jobs.to(torch.float32)\n",
    "                jobs = jobs.to(device)\n",
    "\n",
    "                users = users.to(torch.float32)\n",
    "                users = users.to(device)\n",
    "\n",
    "                entities = entities.to(torch.float32)\n",
    "                entities = entities.to(device)\n",
    "\n",
    "                labels = labels.to(torch.float32)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(jobs, users, entities)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                '''\n",
    "                存一下预测score\n",
    "                '''\n",
    "                # pred_score.extend([j for j in list(outputs.cpu().detach().numpy())])\n",
    "                pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "                y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "            val_losses = total_loss/v_batch\n",
    "            val_acc = accuracy_score(y_label, pred_label)\n",
    "            val_precision = precision_score(y_label, pred_label)\n",
    "            val_recall = recall_score(y_label, pred_label)\n",
    "            val_auc = roc_auc_score(y_label, pred_label)\n",
    "            val_f1 = f1_score(y_label, pred_label)\n",
    "            print('\\nVal | Loss:{:.5f} ACC:{:.5f} Precision:{:.5f} Recall:{:.5f} AUC:{:.5f} F1:{:.5f} Time:{:.6f}'.format(val_losses,val_acc,val_precision, val_recall,val_auc,val_f1, time.time()-start_time))\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_precision = val_precision\n",
    "                best_recall = val_recall\n",
    "                best_f1 = val_f1\n",
    "                best_auc = val_auc\n",
    "                torch.save(model, \"{}/{}.model\".format(model_dir, model_name))\n",
    "                print('save model with acc: {:.3f}, recall: {:.3f}, auc: {:.3f}'.format(best_acc,best_recall,best_auc))\n",
    "        print('------------------------------------------------------')\n",
    "        lr_scheduler.step()\n",
    "        model.train()\n",
    "    return best_acc, best_precision, best_recall, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc6f5931-a2ac-44a7-9d73-d83c8064217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型参数\n",
    "hidden_units = [128, 64, 32]\n",
    "dnn_dropout = 0.7\n",
    "\n",
    "\n",
    "lstm_dim = 768\n",
    "lstm_hd_size = 128\n",
    "num_lstm_layers = 1\n",
    "dropout = 0.7\n",
    "vec_size_2 = 32\n",
    "\n",
    "# 训练参数\n",
    "epoch = 100\n",
    "lr = 0.005\n",
    "# batch_size = 4012\n",
    "batch_size = 32\n",
    "model_dir = './' # change with your model save path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"APJFFF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0086944-9fe6-40e8-abfc-56f889f02c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'feat': 'UserID', 'feat_num': 7921, 'embed_dim': 8}, {'feat': '性别', 'feat_num': 2, 'embed_dim': 8}, {'feat': '专业', 'feat_num': 935, 'embed_dim': 8}, {'feat': 'JobID', 'feat_num': 31647, 'embed_dim': 8}, {'feat': '企业融资阶段', 'feat_num': 9, 'embed_dim': 8}, {'feat': '企业人员规模', 'feat_num': 7, 'embed_dim': 8}, {'feat': '企业休息时间', 'feat_num': 4, 'embed_dim': 8}, {'feat': '企业加班情况', 'feat_num': 3, 'embed_dim': 8}, {'feat': '岗位一级类别', 'feat_num': 21, 'embed_dim': 8}, {'feat': '岗位三级类别', 'feat_num': 530, 'embed_dim': 8}, {'feat': '岗位工作经验', 'feat_num': 5, 'embed_dim': 8}, {'feat': '岗位招聘类型', 'feat_num': 4, 'embed_dim': 8}, {'feat': 'match_degree', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'match_loc_job', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'match_loc_corp', 'feat_num': 2, 'embed_dim': 8}]\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "APJFFF_model = APJFF_connect(lstm_dim, lstm_hd_size, num_lstm_layers, vec_size_2, dropout, feature_columns, hidden_units, dnn_dropout)\n",
    "\n",
    "train_dataset = torch.load(\"/root/autodl-fs/apjfff_dataset/train_3.dataset\")\n",
    "val_dataset = torch.load(\"/root/autodl-fs/apjfff_dataset/val_3.dataset\")\n",
    "test_dataset = torch.load(\"/root/autodl-fs/apjfff_dataset/test_3.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f08e0c-12c4-4a6a-a019-7099b7edb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader导入\n",
    "train_loader = DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0040c4b-db50-4859-a1b1-49872f6d170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "APJFFF_model = torch.load('APJFFF.model') #, map_location=device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8481161e-6e4a-40fb-b003-1d8585310ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training, total parameter:7715507, trainable:7715507\n",
      "\n",
      "[ Epoch1: 1766/1766] \n",
      "\n",
      "Val | Loss:0.48418 ACC:0.81573 Precision:0.81605 Recall:0.81752 AUC:0.81573 F1:0.81679 Time:224.244701\n",
      "save model with acc: 0.816, recall: 0.818, auc: 0.816\n",
      "------------------------------------------------------\n",
      "[ Epoch2: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43922 ACC:0.82826 Precision:0.82575 Recall:0.83421 AUC:0.82823 F1:0.82996 Time:244.811021\n",
      "save model with acc: 0.828, recall: 0.834, auc: 0.828\n",
      "------------------------------------------------------\n",
      "[ Epoch3: 1766/1766] \n",
      "\n",
      "Val | Loss:0.45500 ACC:0.83225 Precision:0.84365 Recall:0.81762 AUC:0.83232 F1:0.83044 Time:255.431698\n",
      "save model with acc: 0.832, recall: 0.818, auc: 0.832\n",
      "------------------------------------------------------\n",
      "[ Epoch4: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39505 ACC:0.83262 Precision:0.85143 Recall:0.80780 AUC:0.83274 F1:0.82904 Time:254.142323\n",
      "save model with acc: 0.833, recall: 0.808, auc: 0.833\n",
      "------------------------------------------------------\n",
      "[ Epoch5: 1766/1766] \n",
      "\n",
      "Val | Loss:0.45624 ACC:0.82837 Precision:0.80619 Recall:0.86676 AUC:0.82818 F1:0.83538 Time:258.706082\n",
      "------------------------------------------------------\n",
      "[ Epoch6: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41698 ACC:0.82911 Precision:0.81807 Recall:0.84858 AUC:0.82902 F1:0.83305 Time:254.167566\n",
      "------------------------------------------------------\n",
      "[ Epoch7: 1766/1766] \n",
      "\n",
      "Val | Loss:0.45644 ACC:0.83251 Precision:0.82477 Recall:0.84647 AUC:0.83244 F1:0.83548 Time:253.108649\n",
      "------------------------------------------------------\n",
      "[ Epoch8: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41695 ACC:0.82959 Precision:0.85413 Recall:0.79691 AUC:0.82975 F1:0.82453 Time:252.210796\n",
      "------------------------------------------------------\n",
      "[ Epoch9: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41442 ACC:0.83432 Precision:0.83822 Recall:0.83052 AUC:0.83433 F1:0.83435 Time:256.027976\n",
      "save model with acc: 0.834, recall: 0.831, auc: 0.834\n",
      "------------------------------------------------------\n",
      "[ Epoch10: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43049 ACC:0.83256 Precision:0.83866 Recall:0.82555 AUC:0.83260 F1:0.83206 Time:253.276314\n",
      "------------------------------------------------------\n",
      "[ Epoch11: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41293 ACC:0.82954 Precision:0.81706 Recall:0.85133 AUC:0.82943 F1:0.83384 Time:254.143669\n",
      "------------------------------------------------------\n",
      "[ Epoch12: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40233 ACC:0.83347 Precision:0.84952 Recall:0.81245 AUC:0.83357 F1:0.83057 Time:254.798926\n",
      "------------------------------------------------------\n",
      "[ Epoch13: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41829 ACC:0.83368 Precision:0.82577 Recall:0.84784 AUC:0.83361 F1:0.83666 Time:252.608306\n",
      "------------------------------------------------------\n",
      "[ Epoch14: 1766/1766] \n",
      "\n",
      "Val | Loss:0.42468 ACC:0.83288 Precision:0.85104 Recall:0.80896 AUC:0.83300 F1:0.82947 Time:254.595693\n",
      "------------------------------------------------------\n",
      "[ Epoch15: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41176 ACC:0.83463 Precision:0.84554 Recall:0.82079 AUC:0.83470 F1:0.83298 Time:256.008259\n",
      "save model with acc: 0.835, recall: 0.821, auc: 0.835\n",
      "------------------------------------------------------\n",
      "[ Epoch16: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41448 ACC:0.83559 Precision:0.85003 Recall:0.81689 AUC:0.83568 F1:0.83313 Time:255.576142\n",
      "save model with acc: 0.836, recall: 0.817, auc: 0.836\n",
      "------------------------------------------------------\n",
      "[ Epoch17: 1766/1766] \n",
      "\n",
      "Val | Loss:0.42737 ACC:0.83410 Precision:0.82266 Recall:0.85387 AUC:0.83401 F1:0.83797 Time:255.769104\n",
      "------------------------------------------------------\n",
      "[ Epoch18: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40679 ACC:0.83463 Precision:0.83532 Recall:0.83559 AUC:0.83463 F1:0.83546 Time:253.395338\n",
      "------------------------------------------------------\n",
      "[ Epoch19: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41109 ACC:0.83644 Precision:0.86362 Recall:0.80093 AUC:0.83661 F1:0.83109 Time:256.004295\n",
      "save model with acc: 0.836, recall: 0.801, auc: 0.837\n",
      "------------------------------------------------------\n",
      "[ Epoch20: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39855 ACC:0.83522 Precision:0.83257 Recall:0.84119 AUC:0.83519 F1:0.83685 Time:248.655861\n",
      "------------------------------------------------------\n",
      "[ Epoch21: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43413 ACC:0.83575 Precision:0.85491 Recall:0.81065 AUC:0.83587 F1:0.83219 Time:256.518046\n",
      "------------------------------------------------------\n",
      "[ Epoch22: 1766/1766] \n",
      "\n",
      "Val | Loss:0.42880 ACC:0.83288 Precision:0.83546 Recall:0.83104 AUC:0.83289 F1:0.83325 Time:253.228976\n",
      "------------------------------------------------------\n",
      "[ Epoch23: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41791 ACC:0.83193 Precision:0.86995 Recall:0.78244 AUC:0.83217 F1:0.82388 Time:255.954070\n",
      "------------------------------------------------------\n",
      "[ Epoch24: 1766/1766] \n",
      "\n",
      "Val | Loss:0.43817 ACC:0.83368 Precision:0.86373 Recall:0.79427 AUC:0.83387 F1:0.82754 Time:252.926394\n",
      "------------------------------------------------------\n",
      "[ Epoch25: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41292 ACC:0.83495 Precision:0.83192 Recall:0.84150 AUC:0.83492 F1:0.83669 Time:249.081644\n",
      "------------------------------------------------------\n",
      "[ Epoch26: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40231 ACC:0.83681 Precision:0.84407 Recall:0.82819 AUC:0.83685 F1:0.83605 Time:254.547671\n",
      "save model with acc: 0.837, recall: 0.828, auc: 0.837\n",
      "------------------------------------------------------\n",
      "[ Epoch27: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40107 ACC:0.83447 Precision:0.86750 Recall:0.79142 AUC:0.83468 F1:0.82772 Time:249.227974\n",
      "------------------------------------------------------\n",
      "[ Epoch28: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39469 ACC:0.83522 Precision:0.84208 Recall:0.82713 AUC:0.83526 F1:0.83454 Time:244.685813\n",
      "------------------------------------------------------\n",
      "[ Epoch29: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41110 ACC:0.83294 Precision:0.82352 Recall:0.84954 AUC:0.83285 F1:0.83632 Time:250.324267\n",
      "------------------------------------------------------\n",
      "[ Epoch30: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41601 ACC:0.83564 Precision:0.83347 Recall:0.84087 AUC:0.83562 F1:0.83716 Time:252.960225\n",
      "------------------------------------------------------\n",
      "[ Epoch31: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40268 ACC:0.83755 Precision:0.86847 Recall:0.79744 AUC:0.83775 F1:0.83144 Time:254.307043\n",
      "save model with acc: 0.838, recall: 0.797, auc: 0.838\n",
      "------------------------------------------------------\n",
      "[ Epoch32: 1766/1766] \n",
      "\n",
      "Val | Loss:0.44400 ACC:0.83187 Precision:0.84227 Recall:0.81868 AUC:0.83194 F1:0.83031 Time:246.139127\n",
      "------------------------------------------------------\n",
      "[ Epoch33: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40380 ACC:0.83596 Precision:0.82795 Recall:0.85017 AUC:0.83589 F1:0.83891 Time:252.779761\n",
      "------------------------------------------------------\n",
      "[ Epoch34: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41833 ACC:0.83596 Precision:0.85099 Recall:0.81646 AUC:0.83606 F1:0.83337 Time:254.271694\n",
      "------------------------------------------------------\n",
      "[ Epoch35: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39535 ACC:0.83633 Precision:0.85422 Recall:0.81298 AUC:0.83645 F1:0.83309 Time:250.907843\n",
      "------------------------------------------------------\n",
      "[ Epoch36: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41231 ACC:0.83575 Precision:0.84885 Recall:0.81889 AUC:0.83583 F1:0.83360 Time:253.465998\n",
      "------------------------------------------------------\n",
      "[ Epoch37: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41516 ACC:0.83787 Precision:0.84920 Recall:0.82354 AUC:0.83794 F1:0.83618 Time:252.412621\n",
      "save model with acc: 0.838, recall: 0.824, auc: 0.838\n",
      "------------------------------------------------------\n",
      "[ Epoch38: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39503 ACC:0.83394 Precision:0.83298 Recall:0.83738 AUC:0.83393 F1:0.83518 Time:247.159765\n",
      "------------------------------------------------------\n",
      "[ Epoch39: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40087 ACC:0.83601 Precision:0.82729 Recall:0.85133 AUC:0.83594 F1:0.83914 Time:249.941544\n",
      "------------------------------------------------------\n",
      "[ Epoch40: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40465 ACC:0.83893 Precision:0.86451 Recall:0.80568 AUC:0.83910 F1:0.83406 Time:249.333325\n",
      "save model with acc: 0.839, recall: 0.806, auc: 0.839\n",
      "------------------------------------------------------\n",
      "[ Epoch41: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41415 ACC:0.83867 Precision:0.84406 Recall:0.83273 AUC:0.83870 F1:0.83836 Time:256.238037\n",
      "------------------------------------------------------\n",
      "[ Epoch42: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40060 ACC:0.83862 Precision:0.85880 Recall:0.81234 AUC:0.83874 F1:0.83493 Time:253.251834\n",
      "------------------------------------------------------\n",
      "[ Epoch43: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39310 ACC:0.83814 Precision:0.84148 Recall:0.83516 AUC:0.83815 F1:0.83831 Time:255.383888\n",
      "------------------------------------------------------\n",
      "[ Epoch44: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39596 ACC:0.83883 Precision:0.86390 Recall:0.80621 AUC:0.83899 F1:0.83406 Time:253.281251\n",
      "------------------------------------------------------\n",
      "[ Epoch45: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39742 ACC:0.83946 Precision:0.84766 Recall:0.82956 AUC:0.83951 F1:0.83851 Time:245.829111\n",
      "save model with acc: 0.839, recall: 0.830, auc: 0.840\n",
      "------------------------------------------------------\n",
      "[ Epoch46: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39785 ACC:0.83750 Precision:0.85928 Recall:0.80907 AUC:0.83764 F1:0.83341 Time:255.575219\n",
      "------------------------------------------------------\n",
      "[ Epoch47: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39417 ACC:0.83623 Precision:0.84892 Recall:0.81995 AUC:0.83631 F1:0.83418 Time:255.991588\n",
      "------------------------------------------------------\n",
      "[ Epoch48: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38996 ACC:0.84201 Precision:0.85423 Recall:0.82661 AUC:0.84209 F1:0.84019 Time:251.190813\n",
      "save model with acc: 0.842, recall: 0.827, auc: 0.842\n",
      "------------------------------------------------------\n",
      "[ Epoch49: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40569 ACC:0.83734 Precision:0.84357 Recall:0.83020 AUC:0.83738 F1:0.83683 Time:253.907341\n",
      "------------------------------------------------------\n",
      "[ Epoch50: 1766/1766] \n",
      "\n",
      "Val | Loss:0.40941 ACC:0.83474 Precision:0.83054 Recall:0.84309 AUC:0.83470 F1:0.83677 Time:256.582693\n",
      "------------------------------------------------------\n",
      "[ Epoch51: 1766/1766] \n",
      "\n",
      "Val | Loss:0.41263 ACC:0.83724 Precision:0.86344 Recall:0.80304 AUC:0.83740 F1:0.83215 Time:255.960577\n",
      "------------------------------------------------------\n",
      "[ Epoch52: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38820 ACC:0.83840 Precision:0.84620 Recall:0.82904 AUC:0.83845 F1:0.83753 Time:255.643880\n",
      "------------------------------------------------------\n",
      "[ Epoch53: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38726 ACC:0.83915 Precision:0.83036 Recall:0.85440 AUC:0.83907 F1:0.84220 Time:255.816347\n",
      "------------------------------------------------------\n",
      "[ Epoch54: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39297 ACC:0.84042 Precision:0.84112 Recall:0.84129 AUC:0.84042 F1:0.84120 Time:245.725683\n",
      "------------------------------------------------------\n",
      "[ Epoch55: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39155 ACC:0.84026 Precision:0.83442 Recall:0.85091 AUC:0.84021 F1:0.84258 Time:254.230879\n",
      "------------------------------------------------------\n",
      "[ Epoch56: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38750 ACC:0.84164 Precision:0.85567 Recall:0.82375 AUC:0.84173 F1:0.83941 Time:254.376178\n",
      "------------------------------------------------------\n",
      "[ Epoch57: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39008 ACC:0.83968 Precision:0.84961 Recall:0.82735 AUC:0.83974 F1:0.83833 Time:256.873587\n",
      "------------------------------------------------------\n",
      "[ Epoch58: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39234 ACC:0.83692 Precision:0.83820 Recall:0.83696 AUC:0.83692 F1:0.83758 Time:255.435695\n",
      "------------------------------------------------------\n",
      "[ Epoch59: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38317 ACC:0.83893 Precision:0.85834 Recall:0.81372 AUC:0.83906 F1:0.83543 Time:252.520172\n",
      "------------------------------------------------------\n",
      "[ Epoch60: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37899 ACC:0.83777 Precision:0.84151 Recall:0.83421 AUC:0.83778 F1:0.83784 Time:254.072355\n",
      "------------------------------------------------------\n",
      "[ Epoch61: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38905 ACC:0.83994 Precision:0.85477 Recall:0.82090 AUC:0.84004 F1:0.83749 Time:253.387320\n",
      "------------------------------------------------------\n",
      "[ Epoch62: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38495 ACC:0.83909 Precision:0.85991 Recall:0.81202 AUC:0.83922 F1:0.83528 Time:253.665495\n",
      "------------------------------------------------------\n",
      "[ Epoch63: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38373 ACC:0.83681 Precision:0.82857 Recall:0.85133 AUC:0.83674 F1:0.83980 Time:253.535986\n",
      "------------------------------------------------------\n",
      "[ Epoch64: 1766/1766] \n",
      "\n",
      "Val | Loss:0.39411 ACC:0.83904 Precision:0.86662 Recall:0.80325 AUC:0.83921 F1:0.83374 Time:256.861037\n",
      "------------------------------------------------------\n",
      "[ Epoch65: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38281 ACC:0.83931 Precision:0.86586 Recall:0.80484 AUC:0.83947 F1:0.83424 Time:256.940168\n",
      "------------------------------------------------------\n",
      "[ Epoch66: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38291 ACC:0.84111 Precision:0.85357 Recall:0.82534 AUC:0.84119 F1:0.83922 Time:260.056520\n",
      "------------------------------------------------------\n",
      "[ Epoch67: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37931 ACC:0.84047 Precision:0.85871 Recall:0.81689 AUC:0.84059 F1:0.83728 Time:258.510866\n",
      "------------------------------------------------------\n",
      "[ Epoch68: 1766/1766] \n",
      "\n",
      "Val | Loss:0.38014 ACC:0.83883 Precision:0.84155 Recall:0.83675 AUC:0.83884 F1:0.83914 Time:258.838223\n",
      "------------------------------------------------------\n",
      "[ Epoch69: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37596 ACC:0.84217 Precision:0.84340 Recall:0.84224 AUC:0.84217 F1:0.84282 Time:257.629235\n",
      "save model with acc: 0.842, recall: 0.842, auc: 0.842\n",
      "------------------------------------------------------\n",
      "[ Epoch70: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37317 ACC:0.84249 Precision:0.85314 Recall:0.82925 AUC:0.84256 F1:0.84102 Time:259.159004\n",
      "save model with acc: 0.842, recall: 0.829, auc: 0.843\n",
      "------------------------------------------------------\n",
      "[ Epoch71: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37895 ACC:0.84148 Precision:0.85123 Recall:0.82946 AUC:0.84154 F1:0.84020 Time:253.104146\n",
      "------------------------------------------------------\n",
      "[ Epoch72: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37449 ACC:0.84440 Precision:0.85563 Recall:0.83041 AUC:0.84447 F1:0.84283 Time:257.905715\n",
      "save model with acc: 0.844, recall: 0.830, auc: 0.844\n",
      "------------------------------------------------------\n",
      "[ Epoch73: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37443 ACC:0.84270 Precision:0.86396 Recall:0.81530 AUC:0.84284 F1:0.83892 Time:254.617440\n",
      "------------------------------------------------------\n",
      "[ Epoch74: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37225 ACC:0.84175 Precision:0.85055 Recall:0.83104 AUC:0.84180 F1:0.84068 Time:257.314162\n",
      "------------------------------------------------------\n",
      "[ Epoch75: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37168 ACC:0.84254 Precision:0.84579 Recall:0.83971 AUC:0.84256 F1:0.84274 Time:254.886096\n",
      "------------------------------------------------------\n",
      "[ Epoch76: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37554 ACC:0.84254 Precision:0.86646 Recall:0.81171 AUC:0.84269 F1:0.83819 Time:255.967940\n",
      "------------------------------------------------------\n",
      "[ Epoch77: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37331 ACC:0.84313 Precision:0.85448 Recall:0.82893 AUC:0.84320 F1:0.84151 Time:255.657454\n",
      "------------------------------------------------------\n",
      "[ Epoch78: 1766/1766] \n",
      "\n",
      "Val | Loss:0.36965 ACC:0.84217 Precision:0.84685 Recall:0.83728 AUC:0.84220 F1:0.84204 Time:255.302457\n",
      "------------------------------------------------------\n",
      "[ Epoch79: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37164 ACC:0.83984 Precision:0.85552 Recall:0.81963 AUC:0.83993 F1:0.83719 Time:255.460916\n",
      "------------------------------------------------------\n",
      "[ Epoch80: 1766/1766] \n",
      "\n",
      "Val | Loss:0.36981 ACC:0.84164 Precision:0.85112 Recall:0.82999 AUC:0.84170 F1:0.84042 Time:260.022133\n",
      "------------------------------------------------------\n",
      "[ Epoch81: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37092 ACC:0.84069 Precision:0.85491 Recall:0.82249 AUC:0.84077 F1:0.83839 Time:257.127939\n",
      "------------------------------------------------------\n",
      "[ Epoch82: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37210 ACC:0.84143 Precision:0.85765 Recall:0.82058 AUC:0.84153 F1:0.83871 Time:254.917547\n",
      "------------------------------------------------------\n",
      "[ Epoch83: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37254 ACC:0.84169 Precision:0.85506 Recall:0.82470 AUC:0.84178 F1:0.83961 Time:256.285440\n",
      "------------------------------------------------------\n",
      "[ Epoch84: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37132 ACC:0.84159 Precision:0.86282 Recall:0.81414 AUC:0.84172 F1:0.83777 Time:259.104064\n",
      "------------------------------------------------------\n",
      "[ Epoch85: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37118 ACC:0.84207 Precision:0.86525 Recall:0.81213 AUC:0.84221 F1:0.83785 Time:251.359763\n",
      "------------------------------------------------------\n",
      "[ Epoch86: 1766/1766] \n",
      "\n",
      "Val | Loss:0.36984 ACC:0.84382 Precision:0.85593 Recall:0.82861 AUC:0.84389 F1:0.84205 Time:254.552089\n",
      "------------------------------------------------------\n",
      "[ Epoch87: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37064 ACC:0.84127 Precision:0.85439 Recall:0.82460 AUC:0.84135 F1:0.83923 Time:256.906742\n",
      "------------------------------------------------------\n",
      "[ Epoch88: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37060 ACC:0.84276 Precision:0.85663 Recall:0.82513 AUC:0.84284 F1:0.84058 Time:255.443952\n",
      "------------------------------------------------------\n",
      "[ Epoch89: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37025 ACC:0.84201 Precision:0.86157 Recall:0.81678 AUC:0.84214 F1:0.83858 Time:256.637074\n",
      "------------------------------------------------------\n",
      "[ Epoch90: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37118 ACC:0.84207 Precision:0.85942 Recall:0.81974 AUC:0.84217 F1:0.83911 Time:248.083420\n",
      "------------------------------------------------------\n",
      "[ Epoch91: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37096 ACC:0.84106 Precision:0.85857 Recall:0.81847 AUC:0.84117 F1:0.83804 Time:254.976312\n",
      "------------------------------------------------------\n",
      "[ Epoch92: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37156 ACC:0.84122 Precision:0.86312 Recall:0.81287 AUC:0.84135 F1:0.83724 Time:260.073520\n",
      "------------------------------------------------------\n",
      "[ Epoch93: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37110 ACC:0.84175 Precision:0.85461 Recall:0.82544 AUC:0.84183 F1:0.83977 Time:253.062596\n",
      "------------------------------------------------------\n",
      "[ Epoch94: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37147 ACC:0.84074 Precision:0.85919 Recall:0.81689 AUC:0.84085 F1:0.83750 Time:257.926445\n",
      "------------------------------------------------------\n",
      "[ Epoch95: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37224 ACC:0.84069 Precision:0.85743 Recall:0.81910 AUC:0.84079 F1:0.83783 Time:258.115194\n",
      "------------------------------------------------------\n",
      "[ Epoch96: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37232 ACC:0.84116 Precision:0.85789 Recall:0.81963 AUC:0.84127 F1:0.83832 Time:258.112350\n",
      "------------------------------------------------------\n",
      "[ Epoch97: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37238 ACC:0.84074 Precision:0.85721 Recall:0.81953 AUC:0.84084 F1:0.83794 Time:258.131335\n",
      "------------------------------------------------------\n",
      "[ Epoch98: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37272 ACC:0.84138 Precision:0.85874 Recall:0.81900 AUC:0.84148 F1:0.83840 Time:256.128380\n",
      "------------------------------------------------------\n",
      "[ Epoch99: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37273 ACC:0.84106 Precision:0.85841 Recall:0.81868 AUC:0.84117 F1:0.83807 Time:255.234595\n",
      "------------------------------------------------------\n",
      "[ Epoch100: 1766/1766] \n",
      "\n",
      "Val | Loss:0.37267 ACC:0.84106 Precision:0.85841 Recall:0.81868 AUC:0.84117 F1:0.83807 Time:256.440159\n",
      "------------------------------------------------------\n",
      "best_acc 0.8444019748367575\n",
      "best_precision 0.8556341861731084\n",
      "best_recall 0.8556341861731084\n",
      "best_f1 0.8428333958925411\n",
      "best_auc 0.8444698971678062\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "best_acc, best_precision, best_recall, best_f1, best_auc = training(epoch, lr, train_loader, val_loader, APJFFF_model, device, model_name, model_dir)\n",
    "\n",
    "# 输出结果（验证集）\n",
    "print('best_acc',best_acc)\n",
    "print('best_precision',best_precision)\n",
    "print('best_recall',best_precision)\n",
    "print('best_f1',best_f1)\n",
    "print('best_auc',best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a4cc60-f49b-47bf-b856-749ae71b9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_loader):\n",
    "    pred_label = []\n",
    "    y_label = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (jobs, users, entities, labels) in enumerate(test_loader):\n",
    "            # 放GPU上运行\n",
    "            jobs = jobs.to(torch.float32)\n",
    "            jobs = jobs.to(device)\n",
    "\n",
    "            users = users.to(torch.float32)\n",
    "            users = users.to(device)\n",
    "\n",
    "            entities = entities.to(torch.float32)\n",
    "            entities = entities.to(device)\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(jobs, users, entities)\n",
    "\n",
    "            pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "\n",
    "        test_acc = accuracy_score(y_label, pred_label)\n",
    "        test_precision = precision_score(y_label, pred_label)\n",
    "        test_recall = recall_score(y_label, pred_label)\n",
    "        test_auc = roc_auc_score(y_label, pred_label)\n",
    "        test_f1 = f1_score(y_label, pred_label)\n",
    "    return test_acc, test_auc, test_precision, test_recall, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ed8cc2b-4e8c-4c73-b930-465fecf056e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.84089823220258\n",
      "test_precision 0.8524013627871194\n",
      "test_recall 0.8524013627871194\n",
      "test_f1 0.8380787724890594\n",
      "test_auc 0.8408832026218134\n"
     ]
    }
   ],
   "source": [
    "# 输出结果(测试集)\n",
    "test_acc, test_auc, test_precision, test_recall, test_f1 = testing(\n",
    "    torch.load('APJFFF.model'), test_loader)\n",
    "print('test_acc', test_acc)\n",
    "print('test_precision', test_precision)\n",
    "print('test_recall', test_precision)\n",
    "print('test_f1', test_f1)\n",
    "print('test_auc', test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
