{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-12T14:52:53.432031800Z",
     "start_time": "2023-12-12T14:52:49.359142700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\gensimbase\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "# import os, sys\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_user_job_all_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your job features list\n",
    "job_features = ['岗位','岗位名称','岗位工作地点','岗位三级类别','岗位招聘人数', '企业上班时间','企业下班时间','企业加班情况','岗位工作经验','岗位学历要求','岗位描述']\n",
    "\n",
    "user_features = ['简历','学校', '专业', '学历', '性别','resume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(x1, ratio_train, ratio_test, ratio_val):\n",
    "    x1_train, x1_middle = train_test_split(x1, test_size=1-ratio_train, random_state=20)\n",
    "    ratio = ratio_val/(ratio_test + ratio_val)\n",
    "    x1_test, x1_validation = train_test_split(x1_middle, test_size=ratio, random_state=20)\n",
    "    return x1_train, x1_test, x1_validation\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = train_test_val_split(dataset, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(input_tensor, dropout_prob):\n",
    "  \"\"\"Perform dropout.\n",
    "  Args:\n",
    "    input_tensor: float Tensor.\n",
    "    dropout_prob: Python float. The probability of dropping out a value (NOT of\n",
    "      *keeping* a dimension as in `torch.nn.dropout`).\n",
    "  Returns:\n",
    "    A version of `input_tensor` with dropout applied.\n",
    "  \"\"\"\n",
    "  if dropout_prob is None or dropout_prob == 0.0:\n",
    "    return input_tensor\n",
    "\n",
    "  x = torch.nn.dropout(1.0 - dropout_prob)\n",
    "  output = x(input_tensor)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer_norm(input_tensor):\n",
    "  \"\"\"Run layer normalization on the last dimension of the tensor.\"\"\"\n",
    "  return torch.nn.LayerNorm(\n",
    "      input_tensor, elementwise_affine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bert_path = '../raochongzhi/SimCSE/pretrained_model/bert_wwm_ext_chinese_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class JobUserDataset(data.Dataset):\n",
    "    '''\n",
    "    Expected data shape like:(data_num, data_len)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, geek, job, geek_sent, job_sent, labels):\n",
    "        self.geek = geek\n",
    "        self.job = job\n",
    "        self.geek_sent = geek_sent\n",
    "        self.job_sent = job_sent\n",
    "        self.labels = labels\n",
    "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_path, output_hidden_states = True)\n",
    "        self.max_feat_len = 16\n",
    "        self.max_sent_len = 256\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        geek_tokens = self.bert_tokenizer(self.geek[idx], padding='max_length', truncation=True,\n",
    "                                          max_length=self.max_feat_len, return_tensors='pt')\n",
    "\n",
    "        job_tokens = self.bert_tokenizer(self.job[idx], padding='max_length', truncation=True,\n",
    "                                         max_length=self.max_feat_len, return_tensors='pt')\n",
    "\n",
    "        geek_sent_tokens = self.bert_tokenizer(self.geek_sent[idx], padding='max_length', truncation=True,\n",
    "                                               max_length=self.max_sent_len, return_tensors='pt')\n",
    "\n",
    "        job_sent_tokens = self.bert_tokenizer(self.job_sent[idx], padding='max_length', truncation=True,\n",
    "                                              max_length=self.max_sent_len, return_tensors='pt')\n",
    "\n",
    "        return geek_tokens['input_ids'], geek_tokens['token_type_ids'], geek_tokens['attention_mask'], job_tokens[\n",
    "            'input_ids'], job_tokens['token_type_ids'], job_tokens['attention_mask'], geek_sent_tokens['input_ids'], \\\n",
    "        geek_sent_tokens['token_type_ids'], geek_sent_tokens['attention_mask'], job_sent_tokens['input_ids'], \\\n",
    "        job_sent_tokens['token_type_ids'], job_sent_tokens['attention_mask'], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer_norm_and_dropout(input_tensor, dropout_prob):\n",
    "  \"\"\"Runs layer normalization followed by dropout.\"\"\"\n",
    "  output_tensor = layer_norm(input_tensor)\n",
    "  output_tensor = dropout(output_tensor, dropout_prob)\n",
    "  return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, embed, pad_size, dropout):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.pe = torch.tensor([[pos / (10000.0 ** (i // 2 * 2.0 / embed)) for i in range(embed)] for pos in range(pad_size)])\n",
    "        self.pe[:, 0::2] = np.sin(self.pe[:, 0::2])\n",
    "        self.pe[:, 1::2] = np.cos(self.pe[:, 1::2])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + nn.Parameter(self.pe, requires_grad=False).to('cuda')\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.attention(x)\n",
    "        out = self.feed_forward(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    '''Scaled Dot-Product Attention '''\n",
    "    def __init__(self):\n",
    "        super(Scaled_Dot_Product_Attention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, scale=None):\n",
    "        '''\n",
    "        Args:\n",
    "            Q: [batch_size, len_Q, dim_Q]\n",
    "            K: [batch_size, len_K, dim_K]\n",
    "            V: [batch_size, len_V, dim_V]\n",
    "        '''\n",
    "        attention = torch.matmul(Q, K.permute(0, 2, 1))\n",
    "        if scale:\n",
    "            attention = attention * scale\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        context = torch.matmul(attention, V)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, dropout=0.0):\n",
    "        super(Multi_Head_Attention, self).__init__()\n",
    "        self.num_head = num_head\n",
    "        assert dim_model % num_head == 0\n",
    "        self.dim_head = dim_model // self.num_head\n",
    "        self.fc_Q = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_K = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.fc_V = nn.Linear(dim_model, num_head * self.dim_head)\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.fc = nn.Linear(num_head * self.dim_head, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        Q = self.fc_Q(x)\n",
    "        K = self.fc_K(x)\n",
    "        V = self.fc_V(x)\n",
    "        Q = Q.view(batch_size * self.num_head, -1, self.dim_head)\n",
    "        K = K.view(batch_size * self.num_head, -1, self.dim_head)\n",
    "        V = V.view(batch_size * self.num_head, -1, self.dim_head)\n",
    "        scale = K.size(-1) ** -0.5\n",
    "        context = self.attention(Q, K, V, scale)\n",
    "\n",
    "        context = context.view(batch_size, -1, self.dim_head * self.num_head)\n",
    "        out = self.fc(context)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Position_wise_Feed_Forward(nn.Module):\n",
    "    def __init__(self, dim_model, hidden, dropout=0.0):\n",
    "        super(Position_wise_Feed_Forward, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_model, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dim_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out + x\n",
    "        out = self.layer_norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_model, num_head, hidden, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attention = Multi_Head_Attention(dim_model, num_head, dropout)\n",
    "        self.feed_forward = Position_wise_Feed_Forward(dim_model, hidden, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.attention(x)\n",
    "        out = self.feed_forward(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BertMatchingModel(nn.Module):\n",
    "    def __init__(self, word_emb_dim, num_heads, hidden_size, dropout, num_layers, fusion):\n",
    "        super(BertMatchingModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(bert_path, output_hidden_states = True)\n",
    "        self.fusion = fusion\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.encoder = Encoder(word_emb_dim *2, num_heads, hidden_size, dropout)\n",
    "\n",
    "        self.encoders = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder)\n",
    "            for _ in range(num_layers)])\n",
    "\n",
    "        self.encoder_2 = Encoder(word_emb_dim *3, num_heads, hidden_size, dropout)\n",
    "        self.encoders_2 = nn.ModuleList([\n",
    "            copy.deepcopy(self.encoder_2)\n",
    "            for _ in range(num_layers)])\n",
    "\n",
    "        self.geek_pool = nn.AdaptiveAvgPool2d((1, word_emb_dim))\n",
    "        self.job_pool = nn.AdaptiveAvgPool2d((1, word_emb_dim))\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            input_size= word_emb_dim * 3,\n",
    "            output_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, geek_tokens_input_ids, geek_tokens_token_type_ids, geek_tokens_attention_mask,\n",
    "                job_tokens_input_ids, job_tokens_token_type_ids, job_tokens_attention_mask,\n",
    "                geek_sent_tokens_input_ids, geek_tokens_sent_token_type_ids, geek_sent_tokens_attention_mask,\n",
    "                job_sent_tokens_input_ids, job_sent_tokens_token_type_ids, job_sent_tokens_attention_mask):\n",
    "\n",
    "        # taxon_embedding\n",
    "        geek_taxon = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 0, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 0, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 0, :].squeeze(\n",
    "                                                  1))[0]).squeeze(\n",
    "            1)  # batch_size * max_len * word_embedding_size -> batch_size * word_embedding_size\n",
    "        job_taxon = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 0, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 0, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 0, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "\n",
    "        # key_ewmbedding\n",
    "        geek_key_0 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 1, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 1, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 1, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        geek_key_1 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 2, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 2, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 2, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        geek_key_2 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 3, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 3, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 3, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        geek_key_3 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 4, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 4, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 4, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        geek_key_4 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 5, :].squeeze(1),\n",
    "                                              token_type_ids=geek_tokens_token_type_ids[:, 5, :].squeeze(1),\n",
    "                                              attention_mask=geek_tokens_attention_mask[:, 5, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "\n",
    "        job_key_0 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 1, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 1, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 1, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_1 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 2, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 2, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 2, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_2 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 3, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 3, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 3, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_3 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 4, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 4, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 4, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_4 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 5, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 5, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 5, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_5 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 6, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 6, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 6, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_6 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 7, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 7, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 7, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_7 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 8, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 8, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 8, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "        job_key_8 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 9, :].squeeze(1),\n",
    "                                            token_type_ids=job_tokens_token_type_ids[:, 9, :].squeeze(1),\n",
    "                                            attention_mask=job_tokens_attention_mask[:, 9, :].squeeze(\n",
    "                                                1))[0]).squeeze(1)\n",
    "\n",
    "        # value_ewmbedding\n",
    "        geek_value_0 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 5, :].squeeze(1),\n",
    "                                                token_type_ids=geek_tokens_token_type_ids[:, 5, :].squeeze(1),\n",
    "                                                attention_mask=geek_tokens_attention_mask[:, 5, :].squeeze(\n",
    "                                                    1))[0]).squeeze(1)\n",
    "        geek_value_1 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 6, :].squeeze(1),\n",
    "                                                token_type_ids=geek_tokens_token_type_ids[:, 6, :].squeeze(1),\n",
    "                                                attention_mask=geek_tokens_attention_mask[:, 6, :].squeeze(\n",
    "                                                    1))[0]).squeeze(1)\n",
    "        geek_value_2 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 7, :].squeeze(1),\n",
    "                                                token_type_ids=geek_tokens_token_type_ids[:, 7, :].squeeze(1),\n",
    "                                                attention_mask=geek_tokens_attention_mask[:, 7, :].squeeze(\n",
    "                                                    1))[0]).squeeze(1)\n",
    "        geek_value_3 = self.geek_pool(self.bert(input_ids=geek_tokens_input_ids[:, 8, :].squeeze(1),\n",
    "                                                token_type_ids=geek_tokens_token_type_ids[:, 8, :].squeeze(1),\n",
    "                                                attention_mask=geek_tokens_attention_mask[:, 8, :].squeeze(\n",
    "                                                    1))[0]).squeeze(1)\n",
    "\n",
    "        geek_value_11 = self.geek_pool(self.bert(input_ids=geek_sent_tokens_input_ids.squeeze(1),\n",
    "                                                 token_type_ids=geek_tokens_sent_token_type_ids.squeeze(1),\n",
    "                                                 attention_mask=geek_sent_tokens_attention_mask.squeeze(\n",
    "                                                     1))[0]).squeeze(1)\n",
    "\n",
    "        job_value_0 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 9, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 9, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 9, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_1 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 10, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 10, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 10, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_2 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 11, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 11, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 11, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_3 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 12, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 12, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 12, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_4 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 13, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 13, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 13, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_5 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 14, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 14, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 14, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_6 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 15, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 15, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 15, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_7 = self.job_pool(self.bert(input_ids=job_tokens_input_ids[:, 16, :].squeeze(1),\n",
    "                                              token_type_ids=job_tokens_token_type_ids[:, 16, :].squeeze(1),\n",
    "                                              attention_mask=job_tokens_attention_mask[:, 16, :].squeeze(\n",
    "                                                  1))[0]).squeeze(1)\n",
    "        job_value_10 = self.job_pool(self.bert(input_ids=job_sent_tokens_input_ids.squeeze(1),\n",
    "                                               token_type_ids=job_sent_tokens_token_type_ids.squeeze(1),\n",
    "                                               attention_mask=job_sent_tokens_attention_mask.squeeze(\n",
    "                                                   1))[0]).squeeze(1)\n",
    "\n",
    "        # Inner interaction\n",
    "        if self.fusion == 'cat':\n",
    "            geek_0 = torch.cat([geek_key_0, geek_value_0], dim=1).unsqueeze(1)  # batch_size * 1 * 2 word_embedding_size\n",
    "            geek_1 = torch.cat([geek_key_1, geek_value_1], dim=1).unsqueeze(1)\n",
    "            geek_2 = torch.cat([geek_key_2, geek_value_2], dim=1).unsqueeze(1)\n",
    "            geek_3 = torch.cat([geek_key_3, geek_value_3], dim=1).unsqueeze(1)\n",
    "            geek_4 = torch.cat([geek_key_4, geek_value_11], dim=1).unsqueeze(1)\n",
    "            job_0 = torch.cat([job_key_0, job_value_0], dim=1).unsqueeze(1)  # batch_size * 1 * word_embedding_size\n",
    "            job_1 = torch.cat([job_key_1, job_value_1], dim=1).unsqueeze(1)\n",
    "            job_2 = torch.cat([job_key_2, job_value_2], dim=1).unsqueeze(1)\n",
    "            job_3 = torch.cat([job_key_3, job_value_3], dim=1).unsqueeze(1)\n",
    "            job_4 = torch.cat([job_key_4, job_value_4], dim=1).unsqueeze(1)\n",
    "            job_5 = torch.cat([job_key_5, job_value_5], dim=1).unsqueeze(1)\n",
    "            job_6 = torch.cat([job_key_6, job_value_6], dim=1).unsqueeze(1)\n",
    "            job_7 = torch.cat([job_key_7, job_value_7], dim=1).unsqueeze(1)\n",
    "            job_8 = torch.cat([job_key_8, job_value_10], dim=1).unsqueeze(1)\n",
    "        else:\n",
    "            geek_0 = (geek_key_0 + geek_value_0).unsqueeze(1)\n",
    "            geek_1 = (geek_key_1 + geek_value_1).unsqueeze(1)\n",
    "            geek_2 = (geek_key_2 + geek_value_2).unsqueeze(1)\n",
    "            geek_3 = (geek_key_3 + geek_value_3).unsqueeze(1)\n",
    "            geek_4 = (geek_key_4 + geek_value_11).unsqueeze(1)\n",
    "\n",
    "            job_0 = (job_key_0 + job_value_0).unsqueeze(1)\n",
    "            job_1 = (job_key_1 + job_value_1).unsqueeze(1)\n",
    "            job_2 = (job_key_2 + job_value_2).unsqueeze(1)\n",
    "            job_3 = (job_key_3 + job_value_3).unsqueeze(1)\n",
    "            job_4 = (job_key_4 + job_value_4).unsqueeze(1)\n",
    "            job_5 = (job_key_5 + job_value_5).unsqueeze(1)\n",
    "            job_6 = (job_key_6 + job_value_6).unsqueeze(1)\n",
    "            job_7 = (job_key_7 + job_value_7).unsqueeze(1)\n",
    "            job_8 = (job_key_8 + job_value_10).unsqueeze(1)\n",
    "        geek = torch.cat([geek_0, geek_1, geek_2, geek_3, geek_4],\n",
    "                         dim=1)  \n",
    "        job = torch.cat([job_0, job_1, job_2, job_3, job_4, job_5, job_6, job_7, job_8],\n",
    "                        dim=1)  \n",
    "\n",
    "        for encoder in self.encoders:\n",
    "            geek, job = encoder(geek), encoder(job)  # batch_size * 12 * word_embedding_size\n",
    "\n",
    "        if self.fusion == 'cat':\n",
    "            geek = torch.cat([torch.repeat_interleave(geek_taxon.unsqueeze(1), repeats=5, dim=1), geek],\n",
    "                             dim=2)  # batch_size * 12 * (3) word_embedding_size\n",
    "            job = torch.cat([torch.repeat_interleave(job_taxon.unsqueeze(1), repeats=9, dim=1), job],\n",
    "                            dim=2)  # batch_size * 11 * (3) word_embedding_size\n",
    "        else:\n",
    "            geek = torch.repeat_interleave(geek_taxon.unsqueeze(1), repeats=5,\n",
    "                                           dim=1) + geek  # batch_size * 5 * word_embedding_size\n",
    "            job = torch.repeat_interleave(job_taxon.unsqueeze(1), repeats=9,\n",
    "                                          dim=1) + job  # batch_size * 9 * word_embedding_size\n",
    "\n",
    "        geek_job = torch.cat([geek, job], dim=1)  # batch_size * 5+9 * (3) word_embedding_size\n",
    "\n",
    "        # print(geek_job.size()) #torch.Size([32, 14, 2304])\n",
    "\n",
    "        for encoder_2 in self.encoders_2:\n",
    "            geek_job = encoder_2(geek_job)  # batch_size * 5+9 * (3) word_embedding_size\n",
    "\n",
    "        geek_vec, job_vec = torch.split(geek_job, (5, 9), dim=1)\n",
    "        geek_vec, job_vec = self.geek_pool(geek_vec).squeeze(1), self.job_pool(job_vec).squeeze(1)\n",
    "        x = torch.cat([job_vec, geek_vec, job_vec - geek_vec], dim=1)\n",
    "\n",
    "        # print(x.size()) #torch.Size([32, 2304])\n",
    "        output = self.mlp(x).squeeze(1) #output: torch.Size([32, 1]) -> torch.Size([32])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_construction(dataset_type):\n",
    "    geek = []\n",
    "    job = []\n",
    "    geek_sent = []\n",
    "    job_sent = []\n",
    "    labels = []\n",
    "    for row in range(len(dataset_type)):\n",
    "        geek.append(user_features + [str(dataset.loc[row, user_features[k]]) for k in range(1,4)])\n",
    "        job.append(job_features + [str(dataset.loc[row, job_features[k]]) for k in range(1,9)])\n",
    "        geek_sent.append(dataset.loc[row, user_features[5]])\n",
    "        job_sent.append(dataset.loc[row, job_features[10]])\n",
    "        labels.append(dataset.loc[row, 'label'])\n",
    "    return geek, job, geek_sent, job_sent, labels\n",
    "\n",
    "geek_tr, job_tr, geek_sent_tr, job_sent_tr, labels_tr = dataset_construction(train_dataset)\n",
    "geek_vl, job_vl, geek_sent_vl, job_sent_vl, labels_vl = dataset_construction(val_dataset)\n",
    "geek_te, job_te, geek_sent_te, job_sent_te, labels_te = dataset_construction(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = JobUserDataset(geek_tr, job_tr, geek_sent_tr, job_sent_tr, labels_tr)\n",
    "val_datasets = JobUserDataset(geek_vl, job_vl, geek_sent_vl, job_sent_vl, labels_vl)\n",
    "test_datasets = JobUserDataset(geek_te, job_te, geek_sent_te, job_sent_te, labels_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# dataloader导入\n",
    "train_loader = DataLoader(dataset= train_datasets, batch_size = batch_size, shuffle = True, drop_last= True)\n",
    "val_loader = DataLoader(dataset = val_datasets, batch_size = batch_size, shuffle = True, drop_last= True)\n",
    "test_loader = DataLoader(dataset = test_datasets, batch_size = batch_size, shuffle = True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training(n_epoch, lr, train, valid, model, device, model_name, model_dir=\"./\"):\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    t_batch = len(train)\n",
    "    v_batch = len(valid)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epoch, eta_min=0, last_epoch=-1)\n",
    "    best_acc, best_precision, best_recall, best_f1, best_auc = 0, 0, 0, 0, 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        start_time = time.time()\n",
    "        total_loss, total_acc = 0, 0\n",
    "        pred_label = []\n",
    "        y_label = []\n",
    "        # training\n",
    "        for i, (jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1, entities_2, entities_3,\n",
    "                entities_4, labels) in enumerate(train):\n",
    "            # 放GPU上运行\n",
    "            jobs_1 = jobs_1.to(device)\n",
    "            jobs_2 = jobs_2.to(device)\n",
    "            jobs_3 = jobs_3.to(device)\n",
    "            jobs_4 = jobs_4.to(device)\n",
    "            users_1 = users_1.to(device)\n",
    "            users_2 = users_2.to(device)\n",
    "            users_3 = users_3.to(device)\n",
    "            users_4 = users_4.to(device)\n",
    "            entities_1 = entities_1.to(device)\n",
    "            entities_2 = entities_2.to(device)\n",
    "            entities_2 = entities_2.to(device)\n",
    "            entities_3 = entities_3.to(device)\n",
    "            entities_4 = entities_4.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            labels = labels.to(torch.float32).to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # 将所有模型参数的梯度置为0\n",
    "            outputs = model(jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1, entities_2,\n",
    "                            entities_3, entities_4)\n",
    "\n",
    "            # print(outputs)\n",
    "            #\n",
    "            # print(labels)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "        print('[ Epoch{}: {}/{}] '.format(epoch + 1, i + 1, t_batch))\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_label = []\n",
    "            y_label = []\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for i, (\n",
    "            jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1, entities_2, entities_3,\n",
    "            entities_4, labels) in enumerate(valid):\n",
    "                # 放GPU上运行\n",
    "                jobs_1 = jobs_1.to(device)\n",
    "                jobs_2 = jobs_2.to(device)\n",
    "                jobs_3 = jobs_3.to(device)\n",
    "                jobs_4 = jobs_4.to(device)\n",
    "                users_1 = users_1.to(device)\n",
    "                users_2 = users_2.to(device)\n",
    "                users_3 = users_3.to(device)\n",
    "                users_4 = users_4.to(device)\n",
    "                entities_1 = entities_1.to(device)\n",
    "                entities_2 = entities_2.to(device)\n",
    "                entities_2 = entities_2.to(device)\n",
    "                entities_3 = entities_3.to(device)\n",
    "                entities_4 = entities_4.to(device)\n",
    "                # labels = labels.to(device)\n",
    "                labels = labels.to(torch.float32).to(device)\n",
    "\n",
    "                outputs = model(jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1,\n",
    "                                entities_2, entities_3, entities_4)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                '''\n",
    "                存一下预测score\n",
    "                '''\n",
    "                # pred_score.extend([j for j in list(outputs.cpu().detach().numpy())])\n",
    "                pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "                y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "            val_losses = total_loss / v_batch\n",
    "            val_acc = accuracy_score(y_label, pred_label)\n",
    "            val_precision = precision_score(y_label, pred_label)\n",
    "            val_recall = recall_score(y_label, pred_label)\n",
    "            val_auc = roc_auc_score(y_label, pred_label)\n",
    "            val_f1 = f1_score(y_label, pred_label)\n",
    "            print(\n",
    "                '\\nVal | Loss:{:.5f} ACC:{:.5f} Precision:{:.5f} Recall:{:.5f} AUC:{:.5f} F1:{:.5f} Time:{:.6f}'.format(\n",
    "                    val_losses, val_acc, val_precision, val_recall, val_auc, val_f1, time.time() - start_time))\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_precision = val_precision\n",
    "                best_recall = val_recall\n",
    "                best_f1 = val_f1\n",
    "                best_auc = val_auc\n",
    "                torch.save(model, \"{}/{}.model\".format(model_dir, model_name))\n",
    "                print(\n",
    "                    'save model with acc: {:.3f}, recall: {:.3f}, auc: {:.3f}'.format(best_acc, best_recall, best_auc))\n",
    "        print('------------------------------------------------------')\n",
    "        lr_scheduler.step()\n",
    "        model.train()\n",
    "    return best_acc, best_precision, best_recall, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "lr = 0.005\n",
    "word_emb_dim = 768\n",
    "num_heads = 8\n",
    "hidden_size = 768\n",
    "num_layers = 1\n",
    "dropout = 0.7\n",
    "fusion = 'cat'\n",
    "model_name = 'INEXIT'\n",
    "model_dir = '/'\n",
    "INEXIT_model = BertMatchingModel(word_emb_dim, num_heads, hidden_size, dropout, num_layers, fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training, total parameter:31833457, trainable:31833457\n",
      "\n",
      "[ Epoch1: 2592/2592] \n",
      "\n",
      "Train | Loss:0.62748 ACC:0.63770 Precision:0.64278 Recall:0.62226 AUC:0.63772 F1:0.63235 Time:79.272038\n",
      "\n",
      "Val | Loss:0.58084 ACC:0.68953 Precision:0.70411 Recall:0.64560 AUC:0.68919 F1:0.67359 Time:85.550087\n",
      "save model with acc: 0.690, recall: 0.646, auc: 0.689\n",
      "------------------------------------------------------\n",
      "[ Epoch2: 2592/2592] \n",
      "\n",
      "Train | Loss:0.56477 ACC:0.70651 Precision:0.72607 Recall:0.66459 AUC:0.70657 F1:0.69397 Time:79.427486\n",
      "\n",
      "Val | Loss:0.55305 ACC:0.71144 Precision:0.72025 Recall:0.68423 AUC:0.71124 F1:0.70178 Time:85.875791\n",
      "save model with acc: 0.711, recall: 0.684, auc: 0.711\n",
      "------------------------------------------------------\n",
      "[ Epoch3: 2592/2592] \n",
      "\n",
      "Train | Loss:0.53428 ACC:0.73257 Precision:0.74423 Recall:0.70988 AUC:0.73261 F1:0.72665 Time:79.399285\n",
      "\n",
      "Val | Loss:0.53675 ACC:0.72761 Precision:0.72770 Recall:0.72075 AUC:0.72756 F1:0.72421 Time:85.065068\n",
      "save model with acc: 0.728, recall: 0.721, auc: 0.728\n",
      "------------------------------------------------------\n",
      "[ Epoch4: 2592/2592] \n",
      "\n",
      "Train | Loss:0.51101 ACC:0.74815 Precision:0.75133 Recall:0.74291 AUC:0.74816 F1:0.74710 Time:79.324644\n",
      "\n",
      "Val | Loss:0.52048 ACC:0.74063 Precision:0.73141 Recall:0.75428 AUC:0.74074 F1:0.74267 Time:85.520097\n",
      "save model with acc: 0.741, recall: 0.754, auc: 0.741\n",
      "------------------------------------------------------\n",
      "[ Epoch5: 2592/2592] \n",
      "\n",
      "Train | Loss:0.48986 ACC:0.76111 Precision:0.75748 Recall:0.76918 AUC:0.76110 F1:0.76328 Time:79.798357\n",
      "\n",
      "Val | Loss:0.50614 ACC:0.75152 Precision:0.74334 Recall:0.76252 AUC:0.75160 F1:0.75281 Time:86.301823\n",
      "save model with acc: 0.752, recall: 0.763, auc: 0.752\n",
      "------------------------------------------------------\n",
      "[ Epoch6: 2592/2592] \n",
      "\n",
      "Train | Loss:0.46797 ACC:0.77713 Precision:0.77526 Recall:0.78144 AUC:0.77713 F1:0.77834 Time:79.520792\n",
      "\n",
      "Val | Loss:0.48968 ACC:0.76678 Precision:0.76581 Recall:0.76347 AUC:0.76676 F1:0.76464 Time:84.982679\n",
      "save model with acc: 0.767, recall: 0.763, auc: 0.767\n",
      "------------------------------------------------------\n",
      "[ Epoch7: 2592/2592] \n",
      "\n",
      "Train | Loss:0.44480 ACC:0.79240 Precision:0.79311 Recall:0.79199 AUC:0.79240 F1:0.79255 Time:79.335651\n",
      "\n",
      "Val | Loss:0.47817 ACC:0.77680 Precision:0.77015 Recall:0.78424 AUC:0.77686 F1:0.77713 Time:85.242037\n",
      "save model with acc: 0.777, recall: 0.784, auc: 0.777\n",
      "------------------------------------------------------\n",
      "[ Epoch8: 2592/2592] \n",
      "\n",
      "Train | Loss:0.42494 ACC:0.80543 Precision:0.80319 Recall:0.80988 AUC:0.80542 F1:0.80652 Time:79.253201\n",
      "\n",
      "Val | Loss:0.46991 ACC:0.78234 Precision:0.77783 Recall:0.78577 AUC:0.78236 F1:0.78178 Time:85.587558\n",
      "save model with acc: 0.782, recall: 0.786, auc: 0.782\n",
      "------------------------------------------------------\n",
      "[ Epoch9: 2592/2592] \n",
      "\n",
      "Train | Loss:0.41020 ACC:0.81389 Precision:0.81007 Recall:0.82076 AUC:0.81388 F1:0.81538 Time:79.667132\n",
      "\n",
      "Val | Loss:0.46604 ACC:0.78758 Precision:0.77946 Recall:0.79758 AUC:0.78765 F1:0.78841 Time:84.867497\n",
      "save model with acc: 0.788, recall: 0.798, auc: 0.788\n",
      "------------------------------------------------------\n",
      "[ Epoch10: 2592/2592] \n",
      "\n",
      "Train | Loss:0.39653 ACC:0.82248 Precision:0.81614 Recall:0.83316 AUC:0.82246 F1:0.82456 Time:79.345652\n",
      "\n",
      "Val | Loss:0.46375 ACC:0.78971 Precision:0.78002 Recall:0.80254 AUC:0.78981 F1:0.79112 Time:85.865964\n",
      "save model with acc: 0.790, recall: 0.803, auc: 0.790\n",
      "------------------------------------------------------\n",
      "[ Epoch11: 2592/2592] \n",
      "\n",
      "Train | Loss:0.38425 ACC:0.82944 Precision:0.82179 Recall:0.84195 AUC:0.82942 F1:0.83175 Time:79.229510\n",
      "\n",
      "Val | Loss:0.46035 ACC:0.79297 Precision:0.78110 Recall:0.80968 AUC:0.79309 F1:0.79513 Time:85.275744\n",
      "save model with acc: 0.793, recall: 0.810, auc: 0.793\n",
      "------------------------------------------------------\n",
      "[ Epoch12: 2592/2592] \n",
      "\n",
      "Train | Loss:0.37234 ACC:0.83484 Precision:0.82619 Recall:0.84869 AUC:0.83482 F1:0.83729 Time:79.701660\n",
      "\n",
      "Val | Loss:0.46023 ACC:0.79442 Precision:0.78406 Recall:0.80830 AUC:0.79452 F1:0.79599 Time:85.694948\n",
      "save model with acc: 0.794, recall: 0.808, auc: 0.795\n",
      "------------------------------------------------------\n",
      "[ Epoch13: 2592/2592] \n",
      "\n",
      "Train | Loss:0.36089 ACC:0.84141 Precision:0.83147 Recall:0.85697 AUC:0.84138 F1:0.84403 Time:79.488598\n",
      "\n",
      "Val | Loss:0.46430 ACC:0.79612 Precision:0.79385 Recall:0.79576 AUC:0.79611 F1:0.79480 Time:85.762350\n",
      "save model with acc: 0.796, recall: 0.796, auc: 0.796\n",
      "------------------------------------------------------\n",
      "[ Epoch14: 2592/2592] \n",
      "\n",
      "Train | Loss:0.35265 ACC:0.84613 Precision:0.83410 Recall:0.86470 AUC:0.84611 F1:0.84912 Time:79.336035\n",
      "\n",
      "Val | Loss:0.46295 ACC:0.79886 Precision:0.78884 Recall:0.81201 AUC:0.79896 F1:0.80026 Time:85.301213\n",
      "save model with acc: 0.799, recall: 0.812, auc: 0.799\n",
      "------------------------------------------------------\n",
      "[ Epoch15: 2592/2592] \n",
      "\n",
      "Train | Loss:0.34303 ACC:0.85059 Precision:0.83745 Recall:0.87060 AUC:0.85057 F1:0.85371 Time:79.472109\n",
      "\n",
      "Val | Loss:0.46638 ACC:0.80035 Precision:0.79838 Recall:0.79955 AUC:0.80034 F1:0.79897 Time:85.415570\n",
      "save model with acc: 0.800, recall: 0.800, auc: 0.800\n",
      "------------------------------------------------------\n",
      "[ Epoch16: 2592/2592] \n",
      "\n",
      "Train | Loss:0.33794 ACC:0.85316 Precision:0.83925 Recall:0.87419 AUC:0.85313 F1:0.85636 Time:79.903430\n",
      "\n",
      "Val | Loss:0.44932 ACC:0.80320 Precision:0.78338 Recall:0.83403 AUC:0.80344 F1:0.80791 Time:86.268020\n",
      "save model with acc: 0.803, recall: 0.834, auc: 0.803\n",
      "------------------------------------------------------\n",
      "[ Epoch17: 2592/2592] \n",
      "\n",
      "Train | Loss:0.33088 ACC:0.85661 Precision:0.84150 Recall:0.87925 AUC:0.85658 F1:0.85996 Time:79.593764\n",
      "\n",
      "Val | Loss:0.47610 ACC:0.80042 Precision:0.79729 Recall:0.80159 AUC:0.80043 F1:0.79943 Time:85.618948\n",
      "------------------------------------------------------\n",
      "[ Epoch18: 2592/2592] \n",
      "\n",
      "Train | Loss:0.32169 ACC:0.86241 Precision:0.84689 Recall:0.88527 AUC:0.86238 F1:0.86565 Time:79.590201\n",
      "\n",
      "Val | Loss:0.47342 ACC:0.80187 Precision:0.78893 Recall:0.82010 AUC:0.80200 F1:0.80422 Time:86.160629\n",
      "------------------------------------------------------\n",
      "[ Epoch19: 2592/2592] \n",
      "\n",
      "Train | Loss:0.31492 ACC:0.86629 Precision:0.85060 Recall:0.88914 AUC:0.86626 F1:0.86944 Time:79.828221\n",
      "\n",
      "Val | Loss:0.48082 ACC:0.80158 Precision:0.79106 Recall:0.81551 AUC:0.80168 F1:0.80310 Time:85.390631\n",
      "------------------------------------------------------\n",
      "[ Epoch20: 2592/2592] \n",
      "\n",
      "Train | Loss:0.30851 ACC:0.86825 Precision:0.85219 Recall:0.89150 AUC:0.86821 F1:0.87140 Time:79.271216\n",
      "\n",
      "Val | Loss:0.48672 ACC:0.80273 Precision:0.78937 Recall:0.82171 AUC:0.80288 F1:0.80521 Time:84.795605\n",
      "------------------------------------------------------\n",
      "best_acc 0.8032045717592593\n",
      "best_precision 0.7833766945091059\n",
      "best_recall 0.7833766945091059\n",
      "best_f1 0.807908208296558\n",
      "best_auc 0.803436909281438\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "best_acc, best_precision, best_recall, best_f1, best_auc = training(epoch, lr, train_loader, val_loader, INEXIT_model, device, model_name, model_dir)\n",
    "\n",
    "# 输出结果（验证集）\n",
    "print('best_acc',best_acc)\n",
    "print('best_precision',best_precision)\n",
    "print('best_recall',best_precision)\n",
    "print('best_f1',best_f1)\n",
    "print('best_auc',best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testing(model, test_loader):\n",
    "    pred_label = []\n",
    "    y_label = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1, entities_2, entities_3, entities_4, labels) in enumerate(test_loader):\n",
    "            # 放GPU上运行\n",
    "            jobs_1 = jobs_1.to(device)\n",
    "            jobs_2 = jobs_2.to(device)\n",
    "            jobs_3 = jobs_3.to(device)\n",
    "            jobs_4 = jobs_4.to(device)\n",
    "            users_1 = users_1.to(device)\n",
    "            users_2 = users_2.to(device)\n",
    "            users_3 = users_3.to(device)\n",
    "            users_4 = users_4.to(device)\n",
    "            entities_1 = entities_1.to(device)\n",
    "            entities_2 = entities_2.to(device)\n",
    "            entities_2 = entities_2.to(device)\n",
    "            entities_3 = entities_3.to(device)\n",
    "            entities_4 = entities_4.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            labels = labels.to(torch.float32).to(device)\n",
    "\n",
    "            outputs = model(jobs_1, jobs_2, jobs_3, jobs_4, users_1, users_2, users_3, users_4, entities_1, entities_2, entities_3, entities_4)\n",
    "\n",
    "            pred_label.extend([0 if i < 0.5 else 1 for i in list(outputs.cpu().detach().numpy())])\n",
    "            y_label.extend(list(labels.cpu().detach().numpy()))\n",
    "\n",
    "        test_acc = accuracy_score(y_label, pred_label)\n",
    "        test_precision = precision_score(y_label, pred_label)\n",
    "        test_recall = recall_score(y_label, pred_label)\n",
    "        test_auc = roc_auc_score(y_label, pred_label)\n",
    "        test_f1 = f1_score(y_label, pred_label)\n",
    "    return test_acc, test_auc, test_precision, test_recall, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc 0.8039641203703703\n",
      "test_precision 0.7866205305651672\n",
      "test_recall 0.7866205305651672\n",
      "test_f1 0.8105425055928412\n",
      "test_auc 0.8038596103061779\n"
     ]
    }
   ],
   "source": [
    "# 输出结果(测试集)\n",
    "test_acc, test_auc, test_precision, test_recall, test_f1 = testing(\n",
    "    torch.load('INEXIT.model'), test_loader)\n",
    "print('test_acc', test_acc)\n",
    "print('test_precision', test_precision)\n",
    "print('test_recall', test_precision)\n",
    "print('test_f1', test_f1)\n",
    "print('test_auc', test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
